"""
Streamlit UI for RAG Document Q&A System.
Professional interface for querying legal documents.
"""
import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

import warnings
import streamlit as st
from loguru import logger
from src.pipeline import RAGPipeline
from src.config import config, VALID_AREAS, get_area_display_name
from src.shared_resources import get_shared_pipeline

# Suppress Streamlit ScriptRunContext warning
warnings.filterwarnings("ignore", message=".*ScriptRunContext.*")

# Configure page
st.set_page_config(
    page_title="RAG Document Q&A",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Configure logging
logger.remove()
logger.add(sys.stderr, level="WARNING")  # Only show warnings in Streamlit


# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .citation {
        background-color: #e8f4f8;
        padding: 0.5rem;
        border-left: 3px solid #1f77b4;
        margin: 0.5rem 0;
        border-radius: 0.25rem;
    }
    .source-chunk {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
        border: 1px solid #dee2e6;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_resource
def load_pipeline():
    """
    Load and cache the RAG pipeline.

    Uses global singleton to avoid multiple Qdrant connections
    when switching between pages.
    """
    with st.spinner("Inicializando sistema RAG..."):
        pipeline = get_shared_pipeline()
        return pipeline


@st.cache_data(ttl=600)  # Cache for 10 minutes
def get_cached_documents(area: str, _pipeline=None) -> list[dict]:
    """
    Get and cache documents for an area.

    PHASE 2.5: Cached to avoid multiple Qdrant connections.
    Uses pipeline's Qdrant client if available.

    Args:
        area: Area code
        _pipeline: Pipeline instance (prefixed with _ to exclude from cache key)
    """
    from src.config import get_documents_for_area

    # Try to reuse pipeline's Qdrant client
    if _pipeline is not None:
        try:
            qdrant_client = _pipeline.vector_search.qdrant_client
            return get_documents_for_area(area, qdrant_client=qdrant_client)
        except Exception as e:
            # If pipeline client fails, fall back to creating new connection
            pass

    # Fallback: create temporary connection
    # This will only be called once per area (cached)
    return get_documents_for_area(area)


def render_sidebar():
    """Render sidebar with configuration."""
    with st.sidebar:
        st.markdown("## ‚öôÔ∏è Configuraci√≥n")

        # Area selector (NUEVO v1.3.0 - separaci√≥n por dominio)
        st.markdown("### üéØ √Årea de Consulta")

        # Create dropdown options with display names
        area_options = {area_code: get_area_display_name(area_code) for area_code in VALID_AREAS.keys()}

        area_display = st.selectbox(
            "Seleccionar √°rea",
            options=list(area_options.values()),
            index=0,  # Default to first option (SGR)
            help="‚ö†Ô∏è IMPORTANTE: Solo se buscar√°n documentos del √°rea seleccionada. Esto garantiza que no se mezclen resultados de diferentes dominios."
        )

        # Get area code from display name
        area = [code for code, name in area_options.items() if name == area_display][0]

        st.info(f"üìö Consultando: **{area_display}**")

        st.markdown("---")

        # PHASE 2.5: Multi-document filter
        st.markdown("### üìë Documentos")

        # Get available documents for the selected area (cached)
        # Only show if pipeline is initialized (avoids Qdrant lock issues)
        pipeline = st.session_state.get("pipeline")
        documento_ids = None  # Default value

        if pipeline is None:
            st.info("‚è≥ Cargando documentos disponibles...")
            available_docs = []
        else:
            available_docs = get_cached_documents(area, _pipeline=pipeline)

        if available_docs:
            # Create dict for display name ‚Üí doc_id mapping
            docs_dict = {doc["nombre"]: doc["id"] for doc in available_docs}

            selected_doc_names = st.multiselect(
                "Filtrar por documentos (vac√≠o = todos)",
                options=list(docs_dict.keys()),
                default=[],
                help=f"üìö {len(available_docs)} documentos disponibles. Selecciona uno o varios, o deja vac√≠o para buscar en todos los documentos del √°rea."
            )

            # Convert selected names to IDs
            documento_ids = [docs_dict[name] for name in selected_doc_names] if selected_doc_names else None

            # Show selection info
            if documento_ids:
                st.success(f"‚úì Buscando en {len(documento_ids)} documento(s) seleccionado(s)")
            else:
                st.info(f"‚ÑπÔ∏è Buscando en TODOS los {len(available_docs)} documentos del √°rea")
        elif pipeline is not None:
            # Pipeline loaded but no documents found
            st.warning(f"‚ö†Ô∏è No hay documentos disponibles en el √°rea '{area_display}'")

        # DEPRECATED: Keep for backward compatibility (not displayed)
        documento_id = None

        st.markdown("---")

        # Advanced settings
        with st.expander("‚öôÔ∏è Configuraci√≥n Avanzada"):
            top_k_retrieval = st.slider(
                "Chunks a recuperar",
                min_value=5,
                max_value=50,
                value=config.retrieval.top_k_retrieval,
                help="N√∫mero de chunks iniciales de b√∫squeda vectorial"
            )

            top_k_rerank = st.slider(
                "Chunks finales (re-ranking)",
                min_value=3,
                max_value=10,
                value=config.retrieval.top_k_rerank,
                help="N√∫mero de chunks despu√©s del re-ranking"
            )

            expand_context = st.checkbox(
                "Expandir contexto",
                value=True,
                help="Incluir chunks adyacentes para m√°s contexto"
            )

            st.markdown("---")

            # Multihop settings (v1.2.0)
            enable_multihop = st.checkbox(
                "Multihop Retrieval",
                value=True,
                help="üöÄ Activa razonamiento multi-paso para queries complejas (condicionales, comparativas, procedurales). M√°s lento pero m√°s preciso."
            )

            if enable_multihop:
                st.info("üí° Multihop detecta autom√°ticamente queries complejas y las descompone en sub-queries para mejor precisi√≥n.")

            st.markdown("---")

            # HyDE settings (NEW v1.3.0)
            enable_hyde = st.checkbox(
                "HyDE (Hypothetical Document Embeddings)",
                value=True,
                help="üî¨ NUEVO: Genera documentos hipot√©ticos para mejorar b√∫squeda sem√°ntica. Especialmente √∫til para queries con terminolog√≠a incorrecta o definiciones. Incrementa costo ~15%."
            )

            if enable_hyde:
                st.info("üí° HyDE traduce autom√°ticamente tu query al estilo del documento y activa fallback si los resultados son pobres.")

            st.markdown("---")

            # Response Validation settings (PHASE 3)
            enable_validation = st.checkbox(
                "‚ö° Validaci√≥n de Completitud (FASE 3)",
                value=True,
                help="üéØ NUEVO: Valida autom√°ticamente si la respuesta est√° completa y hace retry si detecta informaci√≥n faltante. Mejora precisi√≥n +20% en queries complejas. Incrementa costo ~10-20%."
            )

            if enable_validation:
                st.info("üí° FASE 3: Sistema valida la respuesta y busca informaci√≥n adicional si detecta gaps. Ideal para queries con m√∫ltiples aspectos.")

        st.markdown("---")

        # System info
        st.markdown("### üìä Sistema")
        pipeline = st.session_state.get("pipeline")
        if pipeline:
            stats = pipeline.get_stats()
            collection_stats = stats["collection"]

            st.metric(
                "Documentos Indexados",
                collection_stats.get("points_count", 0)
            )
            st.metric(
                "Modelo LLM",
                stats["model"].replace("gpt-", "GPT-")
            )

            if "total_cost" in st.session_state:
                st.metric(
                    "Costo Total Sesi√≥n",
                    f"${st.session_state.total_cost:.6f}"
                )

        st.markdown("---")

        # Example queries
        st.markdown("### üí° Ejemplos de Queries")

        with st.expander("üìù Queries Simples"):
            st.markdown("""
            - ¬øQu√© es un OCAD?
            - ¬øQu√© es el Sistema General de Regal√≠as?
            - Define proyecto de inversi√≥n
            """)

        with st.expander("üîÑ Queries Multihop (Complejas)"):
            st.markdown("""
            **Condicionales:**
            - ¬øPuedo ajustar el cronograma si estoy en fase II?
            - Si mi proyecto es de salud, ¬øqu√© OCAD lo eval√∫a?

            **Comparativas:**
            - Diferencias entre Acuerdo 03/2021 y 13/2025
            - Compara requisitos de CTEI vs infraestructura

            **Procedurales:**
            - Proceso completo desde radicaci√≥n hasta desembolso
            - ¬øC√≥mo solicitar ajuste a proyecto aprobado?
            """)

        with st.expander("üí° C√≥mo Formular Queries Efectivas"):
            st.markdown("""
            **Para mejores resultados:**

            ‚úÖ **S√ç - Menciona secciones espec√≠ficas:**
            - "secci√≥n 18 productos esperados"
            - "secci√≥n 25 fuentes de financiaci√≥n"

            ‚úÖ **S√ç - Usa terminolog√≠a del documento:**
            - "productos esperados" en vez de "productos construidos"
            - "fuentes de financiaci√≥n" en vez de "presupuesto"

            ‚úÖ **S√ç - S√© espec√≠fico:**
            - "¬øQu√© requisitos hay para proyectos de CTEI en fase III?"
            - En vez de: "¬øQu√© requisitos hay?"

            ‚ùå **NO - Queries muy gen√©ricas:**
            - "cu√©ntame del documento"
            - "qu√© dice aqu√≠"
            """)

        # Query tips button
        if st.button("üìñ Ver Gu√≠a Completa de Queries"):
            st.session_state.show_guide = True

        return {
            "area": area,  # v1.3.0 - √Årea de conocimiento obligatoria
            "documento_ids": documento_ids,  # PHASE 2.5 - Filtro multi-documento
            "documento_id": documento_id,  # DEPRECATED - Mantener compatibilidad
            "top_k_retrieval": top_k_retrieval,
            "top_k_rerank": top_k_rerank,
            "expand_context": expand_context,
            "enable_multihop": enable_multihop,
            "enable_hyde": enable_hyde,
            "enable_validation": enable_validation,  # PHASE 3 - Response validation
        }


def render_answer(result):
    """Render the answer section."""
    st.markdown("## üí¨ Respuesta")

    # Show HyDE info if used (NEW v1.3.0)
    hyde_metadata = result.get("hyde_metadata", {})
    if hyde_metadata.get("hyde_used"):
        with st.expander("üî¨ An√°lisis HyDE (Click para detalles)", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                st.metric("HyDE Activado", "S√≠")
                st.metric("Fallback Usado", "S√≠" if hyde_metadata.get("hyde_fallback_used") else "No")

            with col2:
                st.metric("Score Promedio", f"{hyde_metadata.get('hyde_avg_score', 0):.3f}")

            if hyde_metadata.get("hyde_doc"):
                st.markdown("**Documento Hipot√©tico Generado:**")
                st.text(hyde_metadata["hyde_doc"][:300] + "..." if len(hyde_metadata["hyde_doc"]) > 300 else hyde_metadata["hyde_doc"])

            if hyde_metadata.get("hyde_fallback_used"):
                st.success("‚úÖ HyDE fallback mejor√≥ los resultados autom√°ticamente")

    # Show multihop info if used (v1.2.0)
    if result.get("multihop_used"):
        decomposition = result.get("query_decomposition", {})

        with st.expander("üöÄ An√°lisis Multihop (Click para detalles)", expanded=False):
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Tipo de Query", decomposition.get("query_type", "N/A").title())

            with col2:
                st.metric("Complejidad", decomposition.get("complexity", "N/A").title())

            with col3:
                st.metric("Sub-queries", len(decomposition.get("sub_queries", [])))

            if decomposition.get("sub_queries"):
                st.markdown("**Sub-queries ejecutadas:**")
                for i, sq in enumerate(decomposition["sub_queries"], 1):
                    st.markdown(f"{i}. {sq}")

            # Show multihop stats if available
            multihop_stats = result.get("metrics", {}).get("multihop_stats")
            if multihop_stats:
                st.markdown("---")
                st.markdown("**Estad√≠sticas de Retrieval:**")
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"- Total chunks √∫nicos: {multihop_stats.get('total_chunks', 0)}")
                    st.write(f"- Score promedio: {multihop_stats.get('avg_score', 0):.4f}")
                with col2:
                    chunks_by_sources = multihop_stats.get('chunks_by_num_sources', {})
                    if chunks_by_sources:
                        st.write("- Chunks por # de fuentes:")
                        for num, count in sorted(chunks_by_sources.items()):
                            st.write(f"  ‚Ä¢ {num} fuente(s): {count} chunks")

    # Answer text
    answer = result.get("answer", "")
    st.markdown(answer)

    # Citation report in expander
    if result.get("citation_report"):
        with st.expander("üìã Reporte de Citaciones"):
            st.markdown(result["citation_report"])


def render_sources(sources):
    """Render source chunks."""
    st.markdown("## üìö Fuentes Consultadas")

    for i, chunk in enumerate(sources, 1):
        # Check if this chunk was found by multiple sub-queries (multihop)
        sub_query_sources = chunk.get('sub_query_source', [])
        is_multihop_chunk = len(sub_query_sources) > 1

        # Build title with multihop indicator
        title = f"Fuente {i}: {chunk.get('citacion_corta', 'N/A')}"
        score = chunk.get('fused_score', chunk.get('rerank_score', chunk.get('score', 0)))
        title += f" (Score: {score:.3f})"

        if is_multihop_chunk:
            title += f" üîó {len(sub_query_sources)} fuentes"

        with st.expander(title):
            col1, col2 = st.columns([2, 1])

            with col1:
                st.markdown(f"**Documento:** {chunk.get('documento_nombre', 'N/A')}")
                st.markdown(f"**Art√≠culo:** {chunk.get('articulo', 'N/A')}")
                st.markdown(f"**Tipo:** {chunk.get('tipo_contenido', 'N/A').title()}")

                # Show sub-query sources if multihop
                if sub_query_sources:
                    st.markdown(f"**Encontrado por {len(sub_query_sources)} sub-query(s):**")
                    for sq in sub_query_sources[:3]:  # Show max 3
                        st.markdown(f"- _{sq[:80]}..._" if len(sq) > 80 else f"- _{sq}_")

            with col2:
                st.markdown(f"**Tokens:** {chunk.get('longitud_tokens', 0)}")
                if chunk.get('fused_score'):
                    st.markdown(f"**Score Original:** {chunk.get('score', 0):.3f}")
                    st.markdown(f"**Score Fusionado:** {chunk.get('fused_score', 0):.3f}")
                    if chunk.get('boost_factor'):
                        st.markdown(f"**Boost:** {chunk.get('boost_factor', 1.0):.1f}x")
                elif chunk.get('rerank_score'):
                    st.markdown(f"**Score Vectorial:** {chunk.get('original_score', 0):.3f}")
                    st.markdown(f"**Score Re-rank:** {chunk.get('rerank_score', 0):.3f}")

            st.markdown("---")
            st.markdown("**Contenido:**")
            text = chunk.get('texto', '')
            # Show first 500 chars with option to see more
            if len(text) > 500:
                st.text(text[:500] + "...")
                if st.button(f"Ver completo", key=f"show_full_{i}"):
                    st.text(text)
            else:
                st.text(text)


def render_query_guide():
    """Render complete query guide (NEW v1.2.0)."""
    st.markdown("# üìñ Gu√≠a Completa: C√≥mo Formular Queries Efectivas")

    st.markdown("""
    Esta gu√≠a te ayudar√° a obtener mejores resultados del sistema RAG.
    """)

    st.markdown("---")

    # Section 1: Query Types
    st.markdown("## 1Ô∏è‚É£ Tipos de Queries")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### ‚úÖ Queries Simples (Single-hop)")
        st.markdown("""
        **Caracter√≠sticas:**
        - Una sola pregunta directa
        - Respuesta en 1-2 fuentes
        - R√°pidas (3-5 segundos)

        **Ejemplos:**
        ```
        ‚úì ¬øQu√© es un OCAD?
        ‚úì Define proyecto de inversi√≥n
        ‚úì ¬øQu√© es el SGR?
        ```
        """)

    with col2:
        st.markdown("### üöÄ Queries Complejas (Multihop)")
        st.markdown("""
        **Caracter√≠sticas:**
        - Requieren m√∫ltiples pasos
        - Informaci√≥n de varias fuentes
        - M√°s lentas (8-15 segundos)

        **Ejemplos:**
        ```
        ‚úì ¬øPuedo ajustar X si tengo Y?
        ‚úì Diferencias entre A y B
        ‚úì Proceso completo de X a Z
        ```
        """)

    st.markdown("---")

    # Section 2: Best Practices
    st.markdown("## 2Ô∏è‚É£ Mejores Pr√°cticas")

    st.success("""
    ### ‚úÖ S√ç - Menciona secciones espec√≠ficas

    Para **Documento T√©cnico V2**, usa n√∫meros de secci√≥n:
    - "secci√≥n 18 productos esperados"
    - "secci√≥n 25 fuentes de financiaci√≥n"
    - "secci√≥n 6 antecedentes"

    Para **Acuerdo √önico 2025**, usa cap√≠tulos/art√≠culos:
    - "cap√≠tulo 4 ajustes de proyectos"
    - "art√≠culo 4.5.1.2"
    - "t√≠tulo 3"
    """)

    st.success("""
    ### ‚úÖ S√ç - Usa terminolog√≠a del documento

    **Documento T√©cnico:**
    - "productos esperados" (no "productos construidos")
    - "fuentes de financiaci√≥n" (no "presupuesto")
    - "resultados e impactos" (no "resultados del proyecto")

    **Acuerdo √önico:**
    - "viabilizaci√≥n de proyectos" (no "aprobaci√≥n")
    - "ajustes a proyectos" (no "modificaciones")
    - "OCAD" (no "comit√©")
    """)

    st.success("""
    ### ‚úÖ S√ç - S√© espec√≠fico y contextual

    **Mal:**
    - "¬øQu√© requisitos hay?"

    **Bien:**
    - "¬øQu√© requisitos hay para proyectos de CTEI en fase III?"

    **Mal:**
    - "cu√©ntame del proyecto"

    **Bien:**
    - "¬øCu√°les son los productos esperados del proyecto en la secci√≥n 18?"
    """)

    st.error("""
    ### ‚ùå NO - Queries muy gen√©ricas

    Estas queries suelen fallar:
    - "cu√©ntame del documento"
    - "qu√© dice aqu√≠"
    - "dame informaci√≥n"
    - "resumen" (sin especificar qu√© resumir)
    """)

    st.markdown("---")

    # Section 3: Examples by Document
    st.markdown("## 3Ô∏è‚É£ Ejemplos por Documento")

    with st.expander("üìÑ Documento T√©cnico V2", expanded=True):
        st.markdown("""
        **Queries Efectivas:**

        1. **Sobre productos:**
           - ‚úÖ "secci√≥n 18 productos esperados del proyecto"
           - ‚úÖ "¬øcu√°les son los entregables en la secci√≥n 18?"

        2. **Sobre presupuesto:**
           - ‚úÖ "secci√≥n 25 resumen de fuentes de financiaci√≥n"
           - ‚úÖ "¬øcu√°l es el valor total del proyecto en la secci√≥n 25?"

        3. **Sobre metodolog√≠a:**
           - ‚úÖ "secci√≥n 14 metodolog√≠a propuesta"
           - ‚úÖ "¬øcu√°l es la metodolog√≠a en la secci√≥n 14?"

        4. **Queries Complejas (Multihop):**
           - ‚úÖ "¬øcu√°les son los productos esperados y cu√°l es el valor total del proyecto?"
           - ‚úÖ "compara la metodolog√≠a de la secci√≥n 14 con los resultados de la secci√≥n 17"
        """)

    with st.expander("üìÑ Acuerdo √önico 2025"):
        st.markdown("""
        **Queries Efectivas:**

        1. **Sobre ajustes:**
           - ‚úÖ "cap√≠tulo 4 ajustes a proyectos aprobados"
           - ‚úÖ "¬øqu√© variables puedo ajustar seg√∫n el art√≠culo 4.5.1.2?"

        2. **Sobre procedimientos:**
           - ‚úÖ "proceso de viabilizaci√≥n de proyectos"
           - ‚úÖ "¬øc√≥mo se solicita un ajuste a un proyecto aprobado?"

        3. **Queries Complejas (Multihop):**
           - ‚úÖ "¬øpuedo ajustar el cronograma de un proyecto en fase II?"
           - ‚úÖ "diferencias entre proyectos de CTEI y de infraestructura"
        """)

    st.markdown("---")

    # Section 4: Understanding Results
    st.markdown("## 4Ô∏è‚É£ Interpretando Resultados")

    st.info("""
    ### üîç Scores de Relevancia

    - **> 0.8**: Excelente coincidencia
    - **0.6 - 0.8**: Buena coincidencia
    - **0.3 - 0.6**: Coincidencia moderada
    - **< 0.3**: Baja coincidencia (considera reformular)

    Si todos los scores son < 0.3, intenta:
    1. Mencionar la secci√≥n/cap√≠tulo espec√≠fico
    2. Usar terminolog√≠a exacta del documento
    3. Ser m√°s espec√≠fico en tu pregunta
    """)

    st.info("""
    ### üöÄ Indicadores Multihop

    Cuando ves **"üöÄ Multihop Retrieval"**:
    - El sistema detect√≥ que tu query es compleja
    - Se ejecutaron m√∫ltiples b√∫squedas (sub-queries)
    - Chunks marcados con **üîó** fueron encontrados por varias sub-queries (m√°s relevantes)

    **Boost Factor:**
    - 1.0x: Encontrado por 1 sub-query
    - 1.3x: Encontrado por 2 sub-queries (m√°s relevante)
    - 1.5x: Encontrado por 3+ sub-queries (muy relevante)
    """)

    st.markdown("---")

    # Section 5: Tips
    st.markdown("## 5Ô∏è‚É£ Tips Avanzados")

    st.markdown("""
    ### üí° Para Queries Multihop (Complejas)

    1. **Condicionales ("¬øPuedo X si Y?"):**
       - El sistema verificar√° autom√°ticamente ambas condiciones
       - Ejemplo: "¬øPuedo ajustar el cronograma si estoy en fase II?"

    2. **Comparativas ("Diferencias entre A y B"):**
       - El sistema buscar√° informaci√≥n de ambos lados
       - Ejemplo: "Diferencias entre proyectos de CTEI y de infraestructura"

    3. **Procedurales ("Proceso de X"):**
       - El sistema buscar√° m√∫ltiples pasos del proceso
       - Ejemplo: "Proceso completo desde radicaci√≥n hasta desembolso"

    ### ‚ö° Para Mejor Performance

    - Queries simples: Desactiva Multihop (m√°s r√°pido)
    - Queries complejas: Activa Multihop (m√°s preciso)
    - Si no est√°s seguro: D√©jalo activado (se activa solo cuando es necesario)
    """)


def render_metrics(metrics):
    """Render performance metrics."""
    st.markdown("## ‚è±Ô∏è M√©tricas de Performance")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "Tiempo Total",
            f"{metrics.get('total_time', 0):.2f}s"
        )

    with col2:
        st.metric(
            "B√∫squeda",
            f"{metrics.get('search_time', 0):.2f}s"
        )

    with col3:
        st.metric(
            "Generaci√≥n",
            f"{metrics.get('generation_time', 0):.2f}s"
        )

    with col4:
        total_cost = metrics.get('total_cost', metrics.get('llm_cost', 0))
        st.metric(
            "Costo Total",
            f"${total_cost:.6f}"
        )

    # Detailed metrics in expander
    with st.expander("üìä M√©tricas Detalladas"):
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Retrieval:**")
            st.write(f"- Chunks recuperados: {metrics.get('chunks_retrieved', 0)}")
            st.write(f"- Chunks finales: {metrics.get('chunks_reranked', 0)}")
            st.write(f"- Tiempo re-ranking: {metrics.get('rerank_time', 0):.2f}s")

        with col2:
            st.markdown("**Generaci√≥n:**")
            st.write(f"- Tokens entrada: {metrics.get('input_tokens', 0):,}")
            st.write(f"- Tokens salida: {metrics.get('output_tokens', 0):,}")
            st.write(f"- Costo LLM: ${metrics.get('llm_cost', 0):.6f}")

            # HyDE cost if used
            if metrics.get('hyde_cost', 0) > 0:
                st.write(f"- Costo HyDE: ${metrics.get('hyde_cost', 0):.6f}")
                st.write(f"- **Costo Total: ${metrics.get('total_cost', 0):.6f}**")

        # Show indicators for advanced features
        features_used = []
        if metrics.get('multihop_used'):
            features_used.append("üöÄ **Multihop Retrieval** (b√∫squedas m√∫ltiples)")
        if metrics.get('hyde_used'):
            features_used.append("üî¨ **HyDE** (documento hipot√©tico)")

        if features_used:
            st.markdown("---")
            st.markdown("**Caracter√≠sticas Avanzadas Usadas:**")
            for feature in features_used:
                st.info(feature)


def main():
    """Main Streamlit app."""

    # Header
    st.markdown('<p class="main-header">üìö Sistema RAG para Documentos Normativos</p>', unsafe_allow_html=True)
    st.markdown(
        '<p class="sub-header">Consulta inteligente de documentos del Sistema General de Regal√≠as con citaci√≥n legal precisa</p>',
        unsafe_allow_html=True
    )

    # Initialize pipeline
    if "pipeline" not in st.session_state:
        st.session_state.pipeline = load_pipeline()
        st.session_state.total_cost = 0.0
        st.success("‚úÖ Sistema inicializado correctamente")

    pipeline = st.session_state.pipeline

    # Sidebar
    config_params = render_sidebar()

    # Main content
    st.markdown("---")

    # Show query guide if requested
    if st.session_state.get("show_guide", False):
        render_query_guide()
        if st.button("‚ùå Cerrar Gu√≠a"):
            st.session_state.show_guide = False
            st.rerun()
        return

    # Query input
    st.markdown("## üîç Consulta")

    col1, col2 = st.columns([4, 1])

    with col1:
        query = st.text_input(
            "Escribe tu pregunta:",
            placeholder="Ejemplo: ¬øQu√© es un OCAD?",
            label_visibility="collapsed"
        )

    with col2:
        search_button = st.button("üîç Buscar", type="primary", use_container_width=True)

    # Process query
    if search_button and query:
        with st.spinner("Procesando consulta..."):
            try:
                # Execute pipeline
                result = pipeline.query(
                    question=query,
                    area=config_params["area"],  # v1.3.0 - Filtro por √°rea obligatorio
                    documento_ids=config_params["documento_ids"],  # PHASE 2.5 - Filtro multi-documento
                    documento_id=config_params["documento_id"],  # DEPRECATED
                    top_k_retrieval=config_params["top_k_retrieval"],
                    top_k_rerank=config_params["top_k_rerank"],
                    expand_context=config_params["expand_context"],
                    enable_multihop=config_params["enable_multihop"],  # v1.2.0
                    enable_hyde=config_params["enable_hyde"],  # v1.3.0
                    enable_validation=config_params["enable_validation"],  # PHASE 3
                )

                # Update total cost (including HyDE)
                if result.get("success") and result.get("metrics"):
                    st.session_state.total_cost += result["metrics"].get("total_cost", result["metrics"].get("llm_cost", 0))

                # Store result
                st.session_state.last_result = result

            except Exception as e:
                st.error(f"‚ùå Error: {str(e)}")
                return

    # Display results
    if "last_result" in st.session_state:
        result = st.session_state.last_result

        if result.get("success"):
            st.markdown("---")

            # Answer
            render_answer(result)

            st.markdown("---")

            # Metrics
            render_metrics(result.get("metrics", {}))

            st.markdown("---")

            # Sources
            if result.get("sources"):
                render_sources(result["sources"])
        else:
            st.error(f"‚ùå Error: {result.get('error', 'Unknown error')}")

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 2rem;'>
        <p>Sistema RAG MVP - Documentos Normativos SGR</p>
        <p style='font-size: 0.8rem;'>Desarrollado con Qdrant, OpenAI GPT-4o-mini y Streamlit</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
