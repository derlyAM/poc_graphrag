# Changelog

Todos los cambios notables a este proyecto ser√°n documentados en este archivo.

El formato est√° basado en [Keep a Changelog](https://keepachangelog.com/es-ES/1.0.0/),
y este proyecto adhiere a [Versionado Sem√°ntico](https://semver.org/lang/es/).

## [1.1.1] - 2025-10-21

### üîß Hotfix: Eliminaci√≥n de Truncamiento en Embeddings

#### Problema Identificado

Durante las pruebas de queries sobre secciones espec√≠ficas del documento t√©cnico V2 (especialmente ANTECEDENTES), se identific√≥ que:

- Secciones muy largas (>8,000 tokens) se divid√≠an en un solo chunk gigante
- Estos chunks exced√≠an el l√≠mite de embeddings de OpenAI (8,191 tokens)
- El embedding se truncaba autom√°ticamente, perdiendo informaci√≥n sem√°ntica
- La b√∫squeda vectorial no recuperaba estos chunks porque el embedding truncado no matcheaba con las queries

**Ejemplo del problema**:
- Secci√≥n ANTECEDENTES: 50,711 caracteres (12,924 tokens)
- Se creaba 1 solo chunk de 12,924 tokens
- Embedding se truncaba a 8,191 tokens (p√©rdida del 37% del contenido)
- Vector search no recuperaba esta secci√≥n en top-20 resultados

#### Soluci√≥n Implementada

Se reescribi√≥ completamente el m√©todo `_split_long_text()` en `src/ingest/document_hierarchy_processor.py`:

**Mejoras clave**:

1. **L√≠mite de seguridad**: Chunks nunca exceden 8,000 tokens (margen de seguridad vs 8,191)
2. **Overlap inteligente**: Mantiene √∫ltimas N oraciones entre chunks consecutivos para preservar contexto
3. **Divisi√≥n multinivel**:
   - Nivel 1: Divisi√≥n por p√°rrafos (estrategia principal)
   - Nivel 2: Divisi√≥n por oraciones (si p√°rrafos muy largos)
   - Nivel 3: Divisi√≥n por palabras (√∫ltimo recurso para oraciones gigantes)
4. **Universal**: Funciona para CUALQUIER tipo de documento sin l√≥gica espec√≠fica

**Nuevos m√©todos agregados**:
- `_split_with_overlap()`: Divisi√≥n con overlap entre chunks
- `_split_by_paragraphs()`: Divisi√≥n por p√°rrafos
- `_split_into_sentences()`: Detecci√≥n de oraciones con regex
- `_split_by_sentences()`: Divisi√≥n por oraciones
- `_split_by_words()`: Divisi√≥n por palabras (√∫ltimo recurso)
- `_get_overlap_sentences()`: C√°lculo de overlap basado en tokens

#### Resultados

**Antes del fix (v1.1.0)**:
```
Legal (Acuerdo 03/2021):     520 chunks
T√©cnico (DocumentoTecnico_V2): 494 chunks
Total:                       1,014 chunks
Chunks truncados:            ~50 (warnings de truncamiento)
```

**Despu√©s del fix (v1.1.1)**:
```
Legal (Acuerdo 03/2021):     1,080 chunks (+108%)
T√©cnico (DocumentoTecnico_V2): 1,363 chunks (+176%)
Total:                       2,443 chunks (+141%)
Chunks truncados:            0 (cero warnings)
Max tokens por chunk:        ~800 tokens
Promedio tokens por chunk:   ~466 tokens
```

**Secci√≥n ANTECEDENTES espec√≠ficamente**:
- Antes: 1 chunk de 12,924 tokens (truncado a 8,191)
- Despu√©s: 60 chunks (~736 tokens promedio cada uno)
- Overlap: 100 tokens entre chunks consecutivos

#### Limitaci√≥n Conocida

**Problema de dise√±o del RAG** (NO del chunking):

Despu√©s del fix, los chunks existen y est√°n correctamente embebidos, pero queries sobre "secciones espec√≠ficas" no funcionan bien:

- ‚úÖ Query: "metodolog√≠a propuesta" ‚Üí Funciona (busca contenido)
- ‚úÖ Query: "productos esperados" ‚Üí Funciona (busca contenido)
- ‚ùå Query: "qu√© dice la secci√≥n de antecedentes" ‚Üí No funciona (busca metadato)

**Raz√≥n**: La query pregunta por LA SECCI√ìN (metadato estructural), no por EL CONTENIDO sem√°ntico. El embedding del contenido de ANTECEDENTES (estad√≠sticas m√©dicas) no es similar al embedding de "secci√≥n de antecedentes".

**Soluci√≥n futura**: Requiere mejorar el RAG con:
- Query enhancement que extraiga secciones mencionadas y use filtros
- B√∫squeda h√≠brida (vectorial + metadata filtering)
- Reformulaci√≥n de queries gen√©ricas a queries de contenido

#### Validaci√≥n

Tests ejecutados con `scripts/test_multiple_sections.py`:

| Secci√≥n | Query | Resultado | Raz√≥n |
|---------|-------|-----------|-------|
| ANTECEDENTES | "qu√© dice la secci√≥n de antecedentes" | ‚ùå Fallo | Query gen√©rica sobre secci√≥n (problema de RAG) |
| JUSTIFICACI√ìN | "qu√© dice la secci√≥n de justificaci√≥n" | ‚ùå Fallo | Query gen√©rica sobre secci√≥n (problema de RAG) |
| METODOLOG√çA | "cu√°l es la metodolog√≠a propuesta" | ‚úÖ √âxito | Query sobre contenido sem√°ntico |
| PRODUCTOS ESPERADOS | "cu√°les son los productos esperados" | ‚úÖ √âxito | Query sobre contenido sem√°ntico |
| CRONOGRAMA | "cu√°l es el cronograma" | ‚ùå Fallo | Query gen√©rica sobre secci√≥n (problema de RAG) |

**Conclusi√≥n**: El chunking funciona correctamente. Las fallas son por dise√±o del RAG, no por truncamiento.

#### Archivos Modificados

- `src/ingest/document_hierarchy_processor.py`: Reescritura completa de `_split_long_text()` + 5 nuevos m√©todos
- Scripts agregados:
  - `scripts/test_multiple_sections.py`: Validaci√≥n comprehensiva
  - `scripts/debug_vector_search.py`: Debug de b√∫squeda vectorial

#### Migraci√≥n

**‚ö†Ô∏è IMPORTANTE**: Requiere re-ingesti√≥n de documentos

```bash
# Re-ingestar con nuevo chunking
python scripts/01_ingest_pdfs.py
```

**Costo**: ~$0.20 USD (re-embedding de 2,443 chunks)
**Tiempo**: ~2-3 minutos

---

## [1.1.0] - 2025-10-20

### üéâ Arquitectura Jer√°rquica Universal

#### Agregado

- **Sistema de procesamiento jer√°rquico universal** (`src/ingest/document_hierarchy_processor.py`)
  - Procesador √∫nico que maneja cualquier tipo de documento (legal, t√©cnico, financiero, ambiental)
  - Algoritmo universal de detecci√≥n de niveles jer√°rquicos
  - Procesamiento gen√©rico para niveles 1-4
  - Manejo especializado de anexos (nivel 5)
  - Vinculaci√≥n bidireccional parent‚Üîchild
  - Generaci√≥n autom√°tica de `hierarchy_path`

- **Configuraci√≥n centralizada** (`src/ingest/hierarchy_config.py`)
  - Mapeos de claves de estructura a niveles jer√°rquicos
  - Mapeos de tipos de elemento a niveles
  - Nombres de elementos por tipo de documento (legal, technical, financial, environmental, generic)
  - M√©todos helper para consultar configuraci√≥n

- **Scripts de validaci√≥n y diagn√≥stico**
  - `scripts/validate_new_architecture.py`: Validaci√≥n comparativa del sistema nuevo vs anterior
  - `scripts/inspect_tecnico_v2.py`: Inspecci√≥n detallada de documentos procesados

- **Documentaci√≥n completa**
  - `docs/GUIA_USO_PROCESAMIENTO_JERARQUICO.md`: Gu√≠a de usuario con ejemplos pr√°cticos
  - `docs/ARQUITECTURA_TECNICA.md`: Documentaci√≥n t√©cnica para desarrolladores
  - `docs/DISE√ëO_ARQUITECTURA_UNIFICADA.md`: Dise√±o arquitect√≥nico completo
  - Secci√≥n en README.md explicando la nueva arquitectura

#### Mejorado

- **Procesamiento de documentos t√©cnicos**: De 0% a 71.9% de completitud del grafo
  - Ahora detecta 5 niveles jer√°rquicos (antes: 0)
  - 99.8% de chunks con `parent_id` (antes: 0%)
  - 100% de chunks con `hierarchy_path` (antes: 0%)
  - 15.8% de chunks con `children_ids` (antes: 0%)

- **Procesamiento de documentos legales**: Mantiene 71.2% de completitud (sin regresiones)
  - Ahora usa procesador universal en lugar de c√≥digo espec√≠fico
  - Mismo n√∫mero de chunks generados
  - Misma calidad de jerarqu√≠a

- **`src/ingest/chunker.py`**: Refactorizado para usar arquitectura unificada
  - M√©todo `chunk_document()` ahora delega a `DocumentHierarchyProcessor`
  - Fallback a chunking por tama√±o para documentos sin jerarqu√≠a
  - Logs mejorados con informaci√≥n de procesamiento

#### Cambiado

- **Modelo de embeddings**: Actualizado de `text-embedding-3-small` a `text-embedding-3-large`
  - Mayor precisi√≥n en b√∫squeda sem√°ntica
  - Costo: $0.13 por 1M tokens (vs $0.02 anterior)
  - Mejor performance en documentos t√©cnicos

- **Estructura de chunks**: Campos adicionales en payload
  - Todos los chunks ahora tienen `nivel_jerarquico` (0-5)
  - Todos los chunks tienen `hierarchy_path` completo
  - Chunks no-root tienen `parent_id`
  - Chunks con hijos tienen `children_ids` poblado

#### M√©tricas de Impacto

| Documento | Chunks | Niveles | Completitud Grafo | Mejora |
|-----------|--------|---------|-------------------|--------|
| Legal (Acuerdo 03/2021) | 520 | 6 (0-5) | 71.2% | Mantiene calidad |
| T√©cnico (DocumentoTecnico_V2) | 494 | 5 (0,1,2,3,5) | 71.9% | **+71.9%** üéâ |

**Total de chunks procesados**: 1,014
**Costo de re-ingesti√≥n**: $0.013 USD
**Tiempo de procesamiento**: 38 segundos

---

## [1.0.0] - 2025-10-15

### Sistema RAG Base (MVP)

#### Agregado

- **Pipeline de ingesti√≥n completo**
  - Extracci√≥n de PDFs con PyMuPDF4LLM
  - Chunking preservando estructura de documentos legales
  - Generaci√≥n de embeddings con OpenAI
  - Carga a Qdrant vector database

- **Sistema de retrieval**
  - B√∫squeda vectorial en Qdrant
  - Re-ranking con cross-encoder
  - Expansi√≥n de contexto con chunks adyacentes

- **Generaci√≥n de respuestas**
  - Integraci√≥n con GPT-4o-mini
  - Sistema de citaci√≥n legal autom√°tica
  - Validaci√≥n de citaciones
  - Tracking de costos

- **Interfaz de usuario**
  - Aplicaci√≥n Streamlit con UI profesional
  - Visualizaci√≥n de fuentes y m√©tricas
  - Filtros por documento
  - Par√°metros configurables

- **Scripts de utilidad**
  - `scripts/01_ingest_pdfs.py`: Pipeline de ingesti√≥n
  - `scripts/02_test_queries.py`: Testing de queries

- **Infraestructura**
  - Docker Compose para Qdrant
  - Configuraci√≥n con variables de entorno
  - Logging estructurado con loguru

#### Tipos de Documento Soportados

- ‚úÖ Documentos legales (Acuerdos, Decretos, Resoluciones)
- ‚ö†Ô∏è Documentos t√©cnicos (procesamiento b√°sico, sin jerarqu√≠a completa)

#### M√©tricas Iniciales

- **Performance**: ~3-8 segundos por query
- **Costos**: ~$0.0002 por query
- **Precisi√≥n**: Sistema de citaci√≥n con validaci√≥n autom√°tica

---

## Roadmap

### [1.2.0] - Pr√≥xima versi√≥n

#### Planeado

- [ ] Integraci√≥n con Neo4j para grafo de conocimiento
- [ ] Sistema multi-agente con LangGraph
- [ ] API REST con FastAPI
- [ ] Cach√© con Redis
- [ ] Suite de tests completa
- [ ] Soporte para documentos financieros
- [ ] Soporte para documentos ambientales

### [2.0.0] - Futuro

#### En Consideraci√≥n

- [ ] Fact-checking autom√°tico de respuestas
- [ ] Comparaci√≥n entre versiones de documentos
- [ ] Resumen autom√°tico de documentos
- [ ] Extracci√≥n de entidades (NER)
- [ ] Visualizaci√≥n de grafo de conocimiento
- [ ] API p√∫blica para integraci√≥n
- [ ] Dashboard de monitoreo (Prometheus/Grafana)
- [ ] CI/CD automatizado

---

## Notas de Versi√≥n

### Compatibilidad

- **Python**: 3.11+
- **OpenAI API**: Compatible con modelos GPT-4 y text-embedding-3
- **Qdrant**: v1.7.0+

### Dependencias Principales

```
openai>=1.10.0
qdrant-client>=1.7.0
tiktoken>=0.5.2
streamlit>=1.30.0
loguru>=0.7.2
pymupdf4llm>=0.0.5
sentence-transformers>=2.3.0
```

### Migraciones

#### De v1.0.0 a v1.1.0

**‚ö†Ô∏è IMPORTANTE**: Esta versi√≥n requiere re-ingesti√≥n de documentos

```bash
# 1. Backup de datos existentes (opcional)
cp -r ./storage/qdrant_local ./storage/qdrant_backup_v1.0.0

# 2. Re-ingestar documentos con nueva arquitectura
python scripts/01_ingest_pdfs.py

# 3. Validar que todo funciona correctamente
python scripts/validate_new_architecture.py
```

**Cambios en datos**:
- Los chunks ahora incluyen campos `nivel_jerarquico`, `parent_id`, `children_ids`, `hierarchy_path`
- Documentos t√©cnicos ahora tienen estructura jer√°rquica completa
- Mismo esquema general, solo campos adicionales (compatible hacia atr√°s)

**Cambios en c√≥digo**:
- `HierarchicalChunker` ahora delega a `DocumentHierarchyProcessor`
- M√©todos `_chunk_legal_document()` y `_chunk_technical_document()` deprecados (pero a√∫n presentes)
- Nuevo m√≥dulo `hierarchy_config.py` centraliza configuraci√≥n

---

## Reconocimientos

Este proyecto es parte del trabajo acad√©mico de Integrador - Universidad.

**Contribuciones principales**:
- Dise√±o e implementaci√≥n de arquitectura jer√°rquica universal
- Integraci√≥n con OpenAI y Qdrant
- Sistema de citaci√≥n legal autom√°tica
- Documentaci√≥n t√©cnica completa

**Herramientas utilizadas**:
- Claude Code (Anthropic) para asistencia en desarrollo
- OpenAI API para embeddings y generaci√≥n
- Qdrant para b√∫squeda vectorial
- Streamlit para interfaz de usuario

---

**Fecha de √∫ltima actualizaci√≥n**: 2025-10-20
