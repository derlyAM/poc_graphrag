
# AN√ÅLISIS: Integraci√≥n de Documentos de Inteligencia Artificial

**Fecha:** 2025-11-11
**Versi√≥n del Sistema:** v1.2.0
**Objetivo:** Evaluar compatibilidad del sistema actual con documentos de IA sin afectar funcionalidad existente

---

## 1. INVENTARIO DE DOCUMENTOS A PROCESAR

### Documentos en `data_topic_IA/` (10 archivos, ~41MB total)

| # | Documento | Tama√±o | Tipo Detectado | Estructura Esperada |
|---|-----------|--------|----------------|---------------------|
| 1 | **CONPES Colombia - Pol√≠tica nacional de inteligencia artificial.pdf** | 909KB | **Legal/Normativo** | T√≠tulos, Cap√≠tulos, Secciones |
| 2 | **European Union Artificial Intelligence Act a guide.pdf** | 1.1MB | **Legal** | Secciones, Art√≠culos, Anexos |
| 3 | **Facultad de IA Universidad de Caldas.pdf** | 183KB | **Informativo** | Secciones simples |
| 4 | **IEEE - Est√°ndar global de √©tica.pdf** | 426KB | **T√©cnico/Normativo** | Secciones numeradas |
| 5 | **INTELIGENCIA ARTIFICIAL - historia, evoluci√≥n.pdf** | **26MB** ‚ö†Ô∏è | **T√©cnico/Acad√©mico** | Cap√≠tulos, Secciones |
| 6 | **INTELIGENCIA ARTIFICIAL, naturalmente (Nuria Oliver).pdf** | 2.8MB | **Divulgativo** | Cap√≠tulos narrativos |
| 7 | **Introducci√≥n a la IA Generativa Ametic.pdf** | 636KB | **T√©cnico/Comercial** | Secciones con √≠ndice |
| 8 | **La IA y su uso en el sector p√∫blico.pdf** | 6.6MB | **T√©cnico/Pol√≠tico** | Secciones, Subsecciones |
| 9 | **UNESCO - IA y educaci√≥n.pdf** | 897KB | **Acad√©mico/Pol√≠tico** | Secciones |
| 10 | **Gu√≠a sobre IA para estudiantes 2025.pdf** | 2.8MB | **Educativo** | Secciones tem√°ticas |

### Clasificaci√≥n por Tipo de Estructura

```
üìä TIPOS DETECTADOS:
- Legal/Normativo (20%): CONPES, EU AI Act
- T√©cnico/Acad√©mico (40%): IEEE, Historia IA, IA sector p√∫blico, UNESCO
- Divulgativo/Educativo (40%): Facultad Caldas, Nuria Oliver, Ametic, Gu√≠a estudiantes
```

---

## 2. AN√ÅLISIS DE COMPATIBILIDAD CON SISTEMA ACTUAL

### 2.1 ‚úÖ LO QUE FUNCIONAR√çA SIN CAMBIOS

#### A. Pipeline de Extracci√≥n (`pdf_extractor.py`)
**Estado:** ‚úÖ **FUNCIONAL**

```python
# El extractor actual PUEDE procesar estos documentos:

1. Extracci√≥n de texto con PyMuPDF ‚úÖ
   - Funciona con CUALQUIER PDF
   - Preserva estructura b√°sica
   - Soporta multiidioma

2. Detecci√≥n autom√°tica de tipo ‚úÖ
   - _detect_document_type() clasifica: legal, technical, generic
   - Documentos normativos ‚Üí "legal"
   - Documentos con secciones numeradas ‚Üí "technical"
   - Otros ‚Üí "generic"

3. Patrones de detecci√≥n existentes ‚úÖ
   - Legal: T√çTULO, CAP√çTULO, ART√çCULO, PAR√ÅGRAFO
   - T√©cnico: "1. SECTION", "1.1 Subsection", "1.1.1 Detail"
   - Com√∫n: ANEXO
```

**Ejemplo con CONPES:**
```python
# CONPES Colombia tiene:
# - Secciones numeradas ‚Üí Detectado como "technical"
# - Estructura: Resumen ejecutivo > Numerales > Subnumerales
# - FUNCIONAR√Å con patrones t√©cnicos actuales
```

**Ejemplo con EU AI Act:**
```python
# EU AI Act tiene:
# - Art√≠culos, Anexos ‚Üí Detectado como "legal"
# - Estructura similar a Acuerdos SGR
# - FUNCIONAR√Å con patrones legales actuales
```

#### B. Procesador Jer√°rquico (`document_hierarchy_processor.py`)
**Estado:** ‚úÖ **FUNCIONAL (con limitaciones)**

```python
# Procesamiento universal de niveles 0-5:

Nivel 0 (Documento ra√≠z) ‚úÖ
  ‚Üí Funciona para TODOS los documentos
  ‚Üí Crea nodo ra√≠z autom√°ticamente

Nivel 1 (Divisi√≥n Mayor) ‚úÖ
  ‚Üí T√≠tulos (legal) / Secciones (t√©cnico)
  ‚Üí Detecta: "1. SECTION NAME", "T√çTULO 1"

Nivel 2 (Divisi√≥n Media) ‚úÖ
  ‚Üí Cap√≠tulos (legal) / Subsecciones (t√©cnico)
  ‚Üí Detecta: "1.1 Subsection", "CAP√çTULO 1"

Nivel 3 (Unidad B√°sica) ‚úÖ
  ‚Üí Art√≠culos (legal) / Sub-subsecciones (t√©cnico)
  ‚Üí Detecta: "1.1.1 Detail", "ART√çCULO 1.2.3"

Nivel 5 (Anexos) ‚úÖ
  ‚Üí Funciona para TODOS los documentos
  ‚Üí Detecta: "ANEXO I", "ANEXO 1"
```

#### C. Sistema de Embedding y Retrieval
**Estado:** ‚úÖ **FUNCIONAL SIN CAMBIOS**

```python
# Componentes independientes del tipo de documento:

1. OpenAI Embeddings (text-embedding-3-large) ‚úÖ
   - Funciona con CUALQUIER texto
   - 8191 tokens l√≠mite ‚Üí chunking adaptativo ya implementado

2. Qdrant Vector DB ‚úÖ
   - Colecci√≥n "normativa_sgr" puede alojar M√öLTIPLES tipos
   - Metadata filtering permite separar por tipo

3. Re-ranking (cross-encoder) ‚úÖ
   - Agn√≥stico al tipo de documento
   - Funciona con contexto sem√°ntico

4. Multihop Retrieval (v1.2.0) ‚úÖ
   - QueryDecomposer: Analiza consultas complejas
   - MultihopRetriever: B√∫squedas iterativas
   - Funciona independiente del dominio
```

#### D. Interfaz Streamlit
**Estado:** ‚úÖ **FUNCIONAL SIN CAMBIOS**

```python
# UI no hace suposiciones sobre tipo de documento:
- Acepta cualquier query
- Muestra fuentes gen√©ricamente
- Filtros por metadata (habr√≠a que agregar filtro por "area")
```

---

### 2.2 ‚ö†Ô∏è LO QUE FUNCIONAR√çA CON LIMITACIONES

#### A. Metadata Espec√≠fica del Dominio
**Estado:** ‚ö†Ô∏è **PARCIALMENTE COMPATIBLE**

**Problema:**
```python
# Schema actual est√° optimizado para documentos legales SGR:
{
    "titulo": "4",          # ‚úÖ Legal
    "capitulo": "5",        # ‚úÖ Legal
    "articulo": "4.5.1.2",  # ‚úÖ Legal
    "paragrafo": None,      # ‚úÖ Legal

    "seccion": "6",         # ‚úÖ T√©cnico (pero sin usar en SGR)
    "subseccion": None,     # ‚úÖ T√©cnico (pero sin usar en SGR)

    # ‚ùå FALTA:
    "area": None,           # No distingue "IA" vs "SGR"
    "subtema": None,        # No captura "√©tica IA", "regulaci√≥n IA"
    "tipo_contenido": "general"  # Muy gen√©rico
}
```

**Impacto:**
- ‚úÖ Documentos de IA se almacenar√≠an correctamente
- ‚ö†Ô∏è NO habr√≠a forma de filtrar "dame solo documentos de IA"
- ‚ö†Ô∏è Queries mezclar√≠an resultados de SGR + IA sin distinci√≥n clara

#### B. Citaci√≥n y Referencias
**Estado:** ‚ö†Ô∏è **REQUIERE ADAPTACI√ìN**

**Problema:**
```python
# Citaci√≥n actual (_generate_citation):
"Art. 4.5.1.2, Acuerdo 03/2021"  # ‚úÖ Perfecto para SGR

# ¬øQu√© pasa con documentos de IA?
"Sec. 1.2, CONPES Colombia - Pol√≠tica nacional de inteligencia artificial"
# ‚ö†Ô∏è FUNCIONA pero muy largo
# ‚ö†Ô∏è Formato inconsistente entre tipos

"Art. 5, European Union Artificial Intelligence Act a guide"
# ‚ö†Ô∏è Nombre de archivo vs nombre formal del documento
```

**Soluci√≥n necesaria:**
- Normalizaci√≥n de nombres de documentos
- Citaci√≥n adaptativa por tipo

#### C. Query Enhancement
**Estado:** ‚ö†Ô∏è **REQUIERE EXPANSI√ìN**

**Problema:**
```python
# QueryEnhancer actual busca:
- "cap√≠tulo", "art√≠culo", "t√≠tulo", "OCAD", "SGR", "viabilidad"
# ‚ùå NO reconoce t√©rminos de IA:
- "modelo de lenguaje", "√©tica IA", "regulaci√≥n europea", "riesgo alto"
```

**Impacto:**
- ‚ö†Ô∏è Queries espec√≠ficas de IA NO se expandir√≠an adecuadamente
- ‚ö†Ô∏è P√©rdida de precisi√≥n en retrieval

---

### 2.3 ‚ùå LO QUE NO FUNCIONAR√çA

#### A. Estructuras No Est√°ndar
**Problema:** Documentos divulgativos/narrativos sin jerarqu√≠a clara

**Ejemplos:**

1. **Nuria Oliver - Manual de convivencia (2.8MB)**
```markdown
# Estructura detectada:
- Cap√≠tulos narrativos SIN numeraci√≥n est√°ndar
- Secciones con t√≠tulos literarios: "El futuro que nos espera"
- ‚ùå NO matchea patrones: "CAP√çTULO X" ni "1. SECTION"
```

**Resultado esperado:**
```python
doc_type = "generic"  # ‚úÖ Detectado correctamente
structure = {
    "titulos": [],         # ‚ùå Vac√≠o (no hay "T√çTULO X")
    "secciones": [],       # ‚ùå Vac√≠o (no hay "1. SECTION")
    "capitulos": []        # ‚ùå Vac√≠o (no hay "CAP√çTULO X")
}
# ‚Üí Procesado como documento plano (solo nivel 0)
# ‚Üí P√©rdida total de jerarqu√≠a
```

2. **Gu√≠a para Estudiantes 2025 (2.8MB)**
```markdown
# Estructura real:
## ¬øQu√© supone la IA para tu educaci√≥n?
### Tipos de herramientas de IA
#### Herramientas de IA generativa

# ‚ùå NO detectado: Usa markdown headers (##, ###) no capturados
```

**Resultado esperado:**
```python
# Documento procesado como "generic" sin jerarqu√≠a
# ‚Üí Chunks grandes sin estructura
# ‚Üí B√∫squeda menos precisa
```

#### B. Tablas Complejas
**Problema:** PyMuPDF no preserva estructura de tablas

**Ejemplo:** EU AI Act tiene tablas de clasificaci√≥n de riesgo
```
| AI System Type | Risk Level | Obligations |
|----------------|------------|-------------|
| Emotion recognition | High | Full compliance |
| Chatbots | Limited | Transparency only |
```

**Resultado actual:**
```
AI System Type Risk Level Obligations
Emotion recognition High Full compliance
Chatbots Limited Transparency only
# ‚ùå Estructura perdida, dif√≠cil de entender
```

#### C. Contenido Multiidioma
**Problema:** Algunos documentos tienen secciones en ingl√©s

**Ejemplo:** IEEE Standard
```python
# Metadata extraction (_extract_metadata) asume espa√±ol:
if "acuerdo" in filename.lower():  # ‚ùå No detecta "agreement"
if "decreto" in filename.lower():   # ‚ùå No detecta "regulation"
```

**Resultado:**
```python
metadata = {
    "documento_tipo": "unknown",  # ‚ùå No clasificado
    "documento_numero": None      # ‚ùå No extra√≠do
}
```

---

## 3. AN√ÅLISIS POR DOCUMENTO

### üü¢ COMPATIBLES SIN CAMBIOS (30%)

#### 1. **CONPES Colombia** (909KB)
```yaml
Estructura: Secciones numeradas (Resumen ejecutivo > 1. Antecedentes > 1.1...)
Tipo detectado: "technical" ‚úÖ
Funcionar√°: ‚úÖ S√ç
Patrones: Secciones (Nivel 1), Subsecciones (Nivel 2)
Limitaciones: Nombre largo en citaci√≥n
```

#### 2. **EU AI Act** (1.1MB)
```yaml
Estructura: Art√≠culos + Anexos (similar a Acuerdos)
Tipo detectado: "legal" ‚úÖ
Funcionar√°: ‚úÖ S√ç
Patrones: Art√≠culos (Nivel 3), Anexos (Nivel 5)
Limitaciones: Algunos art√≠culos sin numeraci√≥n est√°ndar
```

#### 3. **IEEE - Est√°ndar de √©tica** (426KB)
```yaml
Estructura: Secciones numeradas t√©cnicas
Tipo detectado: "technical" ‚úÖ
Funcionar√°: ‚úÖ S√ç
Patrones: Secciones (1., 1.1, 1.1.1)
Limitaciones: Ninguna cr√≠tica
```

---

### üü° COMPATIBLES CON LIMITACIONES (40%)

#### 4. **Introducci√≥n IA Generativa Ametic** (636KB)
```yaml
Estructura: √çndice + Secciones con t√≠tulos descriptivos
Tipo detectado: "technical" o "generic" (depende de numeraci√≥n)
Funcionar√°: ‚ö†Ô∏è PARCIALMENTE
Patrones: Detectar√° secciones numeradas si existen
Limitaciones:
  - Contenido comercial (menos formal)
  - Posibles secciones sin numeraci√≥n
  - Requiere revisi√≥n de extracci√≥n
```

#### 5. **IA en sector p√∫blico** (6.6MB)
```yaml
Estructura: Cap√≠tulos + Secciones (mezcla legal/t√©cnico)
Tipo detectado: Probablemente "technical"
Funcionar√°: ‚ö†Ô∏è PARCIALMENTE
Patrones: Secciones numeradas
Limitaciones:
  - Documento grande ‚Üí m√∫ltiples chunks por secci√≥n
  - Posible mezcla de formatos
```

#### 6. **Historia y evoluci√≥n de IA** (26MB ‚ö†Ô∏è CR√çTICO)
```yaml
Estructura: Libro t√©cnico (cap√≠tulos + secciones)
Tipo detectado: "technical" o "generic"
Funcionar√°: ‚ö†Ô∏è PARCIALMENTE
Problemas:
  - TAMA√ëO EXTREMO (26MB) ‚Üí Alto costo embedding
  - Posiblemente 500-1000 chunks ‚Üí $0.65 en embeddings
  - Requiere pre-filtrado: ¬øProcesar solo cap√≠tulos clave?
  - Tiempo de procesamiento: ~15-20 minutos
Recomendaci√≥n: üî¥ NO procesar completo, extraer cap√≠tulos selectos
```

#### 7. **UNESCO - IA y educaci√≥n** (897KB)
```yaml
Estructura: Documento de pol√≠tica (secciones + recomendaciones)
Tipo detectado: "technical"
Funcionar√°: ‚ö†Ô∏è PARCIALMENTE
Limitaciones:
  - Estructura mixta (narrativo + listas)
  - Requiere validaci√≥n de patrones
```

---

### üî¥ INCOMPATIBLES (Requieren trabajo adicional) (30%)

#### 8. **Facultad de IA Universidad de Caldas** (183KB)
```yaml
Estructura: Folleto informativo (sin jerarqu√≠a formal)
Tipo detectado: "generic"
Funcionar√°: ‚ùå SOLO NIVEL 0 (documento plano)
Problemas:
  - No tiene estructura legal ni t√©cnica est√°ndar
  - Probablemente secciones con t√≠tulos literarios
  - Perder√° contexto jer√°rquico
Soluci√≥n:
  - Detecci√≥n de markdown headers (## Secci√≥n)
  - Detecci√≥n de t√≠tulos por formato (MAY√öSCULAS, negritas)
```

#### 9. **Nuria Oliver - Manual de convivencia** (2.8MB)
```yaml
Estructura: Libro divulgativo (cap√≠tulos narrativos)
Tipo detectado: "generic"
Funcionar√°: ‚ùå SOLO NIVEL 0
Problemas:
  - Cap√≠tulos sin numeraci√≥n ("El futuro que nos espera")
  - Estructura narrativa, no normativa
  - P√©rdida total de jerarqu√≠a
Soluci√≥n:
  - Parser de TOC (Table of Contents)
  - Detecci√≥n de cap√≠tulos por keywords ("Cap√≠tulo", "Parte")
  - Regex m√°s flexible
```

#### 10. **Gu√≠a para estudiantes 2025** (2.8MB)
```yaml
Estructura: Gu√≠a educativa (secciones markdown)
Tipo detectado: "generic"
Funcionar√°: ‚ùå SOLO NIVEL 0
Problemas:
  - Usa markdown (##, ###, ####) ‚Üí NO detectado
  - Secciones con emojis: "üìä TIPOS DETECTADOS"
  - Listas bullet points como estructura
Soluci√≥n:
  - Parser de markdown headers
  - Detecci√≥n de emojis como marcadores
```

---

## 4. RESUMEN DE COMPATIBILIDAD

### Matriz de Compatibilidad

| Componente | Compatible | Con Limitaciones | Incompatible | Acci√≥n Requerida |
|------------|-----------|------------------|--------------|------------------|
| **Extracci√≥n PDF** | ‚úÖ 100% | - | - | Ninguna |
| **Detecci√≥n tipo doc** | ‚úÖ 70% | ‚ö†Ô∏è 30% | - | Mejorar patrones gen√©ricos |
| **Procesamiento jer√°rquico** | ‚úÖ 30% | ‚ö†Ô∏è 40% | ‚ùå 30% | Agregar parsers adicionales |
| **Chunking** | ‚úÖ 100% | - | - | Ninguna |
| **Embedding** | ‚úÖ 100% | - | - | Ninguna |
| **Retrieval** | ‚úÖ 100% | - | - | Ninguna |
| **Metadata** | ‚ö†Ô∏è 50% | ‚ö†Ô∏è 50% | - | Agregar campo "area" |
| **Citaci√≥n** | ‚ö†Ô∏è 60% | ‚ö†Ô∏è 40% | - | Normalizar nombres |
| **Query Enhancement** | - | ‚ö†Ô∏è 100% | - | Agregar t√©rminos IA |

### Por Tipo de Documento

```
üìä COMPATIBILIDAD GLOBAL:

üü¢ ALTA (30%):     CONPES, EU AI Act, IEEE Standard
üü° MEDIA (40%):    Ametic, Sector P√∫blico, Historia IA, UNESCO
üî¥ BAJA (30%):     Facultad Caldas, Nuria Oliver, Gu√≠a Estudiantes

PROMEDIO PONDERADO: ~60% compatible sin cambios
```

---

## 5. IMPACTO EN SISTEMA ACTUAL

### ‚úÖ LO QUE NO SE ROMPER√çA

1. **Documentos SGR existentes**
   - Siguen funcionando EXACTAMENTE igual
   - Ning√∫n cambio en su procesamiento
   - Metadata preservada

2. **Pipeline de ingesti√≥n**
   - Puede ejecutarse SIMULT√ÅNEAMENTE para ambos tipos
   - `scripts/01_ingest_pdfs.py` funciona sin cambios
   - Qdrant soporta m√∫ltiples tipos en misma colecci√≥n

3. **B√∫squedas vectoriales**
   - Algoritmo id√©ntico
   - Cosine similarity agn√≥stico al dominio
   - Re-ranking funciona igual

4. **Multihop Retrieval**
   - QueryDecomposer analiza complejidad (independiente del dominio)
   - MultihopRetriever hace b√∫squedas iterativas (funciona con IA)
   - Fusion scoring combina chunks (universal)

### ‚ö†Ô∏è LO QUE PODR√çA DEGRADARSE

1. **Precisi√≥n de retrieval SIN filtros**
   ```python
   # Query: "¬øQu√© es un OCAD?"
   # Resultado SIN filtro de √°rea:
   - Chunks de SGR (‚úÖ CORRECTO)
   - Chunks de IA que mencionen "organismo" (‚ùå RUIDO)

   # Soluci√≥n: Filtro por metadata["area"] = "sgr"
   ```

2. **Calidad de citaciones mixtas**
   ```python
   # Respuesta con chunks de ambos dominios:
   "Los OCAD eval√∫an proyectos (Art. 4.5, Acuerdo 03/2021).
    La IA puede optimizar procesos (Sec. 2.3, CONPES Colombia - Pol√≠tica nacional de inteligencia artificial)."

   # ‚ö†Ô∏è Formato inconsistente, pero NO ROTO
   ```

3. **Performance de embeddings**
   ```python
   # Si procesamos todos los documentos IA:
   Chunks SGR actuales: ~500 chunks
   Chunks IA estimados: ~1,500 chunks (con el libro grande)

   Total: 2,000 chunks
   Costo embeddings: +$0.26 (uno solo, no recurrente)
   Tama√±o colecci√≥n Qdrant: +15MB (despreciable)
   Latencia b√∫squeda: +50ms (aceptable)
   ```

---

## 6. RECOMENDACIONES IMPLEMENTACI√ìN

### FASE 1: PRUEBA DE CONCEPTO (Sin cambios al sistema) ‚≠ê RECOMENDADO

**Objetivo:** Validar compatibilidad con m√≠nima fricci√≥n

**Documentos a probar:**
1. ‚úÖ **CONPES Colombia** (alta compatibilidad)
2. ‚úÖ **EU AI Act** (alta compatibilidad)
3. ‚ö†Ô∏è **Gu√≠a Estudiantes** (baja compatibilidad - caso de prueba)

**Pasos:**
```bash
# 1. Crear copia de seguridad de Qdrant
cp -r storage/qdrant_local storage/qdrant_backup_20251111

# 2. Copiar 3 documentos a carpeta temporal
mkdir data/test_ia
cp "data_topic_IA/CONPES Colombia"*.pdf data/test_ia/
cp "data_topic_IA/European Union"*.pdf data/test_ia/
cp "data_topic_IA/la-Guia"*.pdf data/test_ia/

# 3. Modificar script de ingesti√≥n (TEMPORAL)
# Editar scripts/01_ingest_pdfs.py:
# - Cambiar data_dir a "data/test_ia"
# - Agregar metadata["area"] = "inteligencia_artificial"

# 4. Ejecutar ingesti√≥n
python scripts/01_ingest_pdfs.py

# 5. Probar queries en Streamlit
streamlit run app/streamlit_app.py
```

**Queries de validaci√≥n:**
```python
# Query 1 (CONPES - compatible):
"¬øCu√°les son los objetivos de la pol√≠tica nacional de IA en Colombia?"

# Query 2 (EU AI Act - compatible):
"¬øQu√© sistemas de IA se consideran de alto riesgo?"

# Query 3 (Gu√≠a - incompatible):
"¬øQu√© herramientas de IA generativa recomienda la gu√≠a?"
# ‚Üí Esperado: Respuesta pobre si no detect√≥ estructura
```

**M√©tricas a observar:**
- ‚úÖ Chunks creados por documento
- ‚úÖ Distribuci√≥n de niveles jer√°rquicos
- ‚úÖ Calidad de citaciones
- ‚úÖ Precisi√≥n de respuestas

**Criterio de √©xito:**
- CONPES y EU AI Act: ‚â•80% precisi√≥n
- Gu√≠a: Respuesta aceptable aunque sin jerarqu√≠a

---

### FASE 2: MEJORAS M√çNIMAS (Si Fase 1 pasa)

**Cambios necesarios:**

#### A. Agregar Campo "area" en Metadata
```python
# src/ingest/document_hierarchy_processor.py
# En _create_chunk():

chunk = {
    # ... campos actuales ...

    # NUEVO:
    "area": metadata.get("area", "general"),  # sgr | inteligencia_artificial | general
    "tags": metadata.get("tags", []),         # ["regulaci√≥n", "√©tica", "educaci√≥n"]
}
```

#### B. Normalizar Nombres de Documentos
```python
# src/ingest/pdf_extractor.py
# En _extract_metadata():

DOCUMENT_NAME_MAP = {
    "conpes_colombia_politica_nacional_de_inteligencia_artificial": "CONPES 4144/2025",
    "european_union_artificial_intelligence_act_a_guide": "EU AI Act",
    "la_guia_sobre_inteligencia_artificial_para_estudiantes_2025": "Gu√≠a IA Estudiantes 2025",
    # ... etc
}

doc_id = filename.lower().replace(" ", "_").replace("-", "_")
doc_nombre = DOCUMENT_NAME_MAP.get(doc_id, filename.title())
```

#### C. Extender Query Enhancement
```python
# src/pipeline/query_enhancer.py
# En _detect_keywords():

IA_KEYWORDS = {
    "modelo de lenguaje": ["llm", "gpt", "transformer"],
    "etica ia": ["sesgo", "fairness", "transparencia"],
    "regulacion": ["ai act", "conpes", "normativa"],
    # ... etc
}
```

#### D. Filtro por √Årea en UI
```python
# app/streamlit_app.py
# En sidebar:

area_filter = st.selectbox(
    "√Årea de consulta",
    options=["Todas", "Sistema General de Regal√≠as", "Inteligencia Artificial"],
    index=0
)

# En retrieval:
filters = {}
if area_filter == "Sistema General de Regal√≠as":
    filters["area"] = "sgr"
elif area_filter == "Inteligencia Artificial":
    filters["area"] = "inteligencia_artificial"
```

**Estimaci√≥n de esfuerzo:**
- Desarrollo: 4-6 horas
- Pruebas: 2 horas
- **Total:** ~1 d√≠a de trabajo

---

### FASE 3: MEJORAS AVANZADAS (Opcional, futuro)

#### A. Parser de Estructuras No Est√°ndar
```python
# Nuevo archivo: src/ingest/advanced_parsers.py

class MarkdownParser:
    """Detecta headers markdown (##, ###, ####)"""

class TOCParser:
    """Extrae Table of Contents y mapea a jerarqu√≠a"""

class StyleBasedParser:
    """Detecta t√≠tulos por formato (tama√±o fuente, negritas)"""
```

#### B. Detecci√≥n de Tablas
```python
# Usar: camelot-py o tabula-py
# Extraer tablas como chunks especiales
chunk["tipo_contenido"] = "tabla"
chunk["tabla_data"] = extracted_table_dict
```

#### C. Procesamiento Selectivo de Documentos Grandes
```python
# Para "Historia IA.pdf" (26MB):
# 1. Extraer TOC
# 2. Permitir al usuario seleccionar cap√≠tulos
# 3. Procesar SOLO cap√≠tulos seleccionados
```

**Estimaci√≥n de esfuerzo:**
- Desarrollo: 2-3 semanas
- Pruebas: 1 semana
- **Total:** ~1 mes

---

## 7. COSTOS ESTIMADOS

### Costos de Procesamiento (Una sola vez)

| Escenario | Chunks | Tokens | Costo Embeddings | Tiempo Proc. |
|-----------|--------|--------|------------------|--------------|
| **Fase 1 (3 docs)** | ~150 | ~75k | **$0.01** | ~2 min |
| **Todos (sin libro grande)** | ~600 | ~300k | **$0.04** | ~8 min |
| **Todos (con libro grande)** | ~1,500 | ~750k | **$0.10** | ~20 min |

### Costos de Consulta (Recurrente)

```python
# Costo por query:
Embedding query (1 llamada): $0.00002
LLM generation (GPT-4o-mini): $0.0015 promedio (10k tokens in + 2k out)

Total por query: ~$0.0015
100 queries/d√≠a = $0.15/d√≠a = $4.50/mes (sin cambios)
```

**Conclusi√≥n:** Impacto de costos DESPRECIABLE

---

## 8. PLAN DE ACCI√ìN RECOMENDADO

### ‚úÖ AHORA (Esta semana)

1. **Ejecutar Fase 1** - Prueba de concepto con 3 documentos
2. **Validar compatibilidad** con queries de prueba
3. **Documentar hallazgos** en este archivo

### üìã CORTO PLAZO (Pr√≥ximas 2 semanas)

4. **Si Fase 1 exitosa:** Implementar Fase 2 (mejoras m√≠nimas)
5. **Procesar documentos compatibles** (CONPES, EU AI Act, IEEE, Ametic)
6. **Agregar filtros por √°rea** en UI

### üöÄ MEDIANO PLAZO (1-2 meses)

7. **Evaluar necesidad** de Fase 3 (parsers avanzados)
8. **Procesar documentos incompatibles** si hay demanda
9. **Optimizar** seg√∫n m√©tricas de uso real

---

## 9. RIESGOS Y MITIGACIONES

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|---------|------------|
| **Degradaci√≥n de b√∫squedas SGR** | Baja | Alto | Filtros por √°rea + backup Qdrant |
| **Documentos incompatibles generan ruido** | Media | Medio | Procesarlos DESPU√âS de validar compatibles |
| **Libro 26MB colapsa pipeline** | Baja | Bajo | Excluir de procesamiento inicial |
| **Usuarios confunden dominios en respuestas** | Media | Medio | Indicador visual de √°rea en UI |
| **Citaciones inconsistentes** | Alta | Bajo | Normalizaci√≥n de nombres (Fase 2) |

---

## 10. CONCLUSIONES

### ‚úÖ COMPATIBILIDAD GENERAL: **BUENA (60-70%)**

El sistema actual **PUEDE** procesar documentos de IA con las siguientes consideraciones:

1. **‚úÖ Sin cambios al c√≥digo:**
   - 30% de documentos (CONPES, EU AI Act, IEEE) funcionar√°n PERFECTAMENTE
   - 40% funcionar√°n ACEPTABLEMENTE (sin jerarqu√≠a completa)

2. **‚úÖ Con cambios m√≠nimos (Fase 2):**
   - 70% de documentos funcionar√°n BIEN
   - Mejora significativa en UX (filtros, citaciones)

3. **‚ö†Ô∏è Con trabajo adicional (Fase 3):**
   - 100% de documentos procesables
   - Requiere inversi√≥n de ~1 mes

### üéØ RECOMENDACI√ìN FINAL

**PROCEDER con enfoque incremental:**

1. ‚úÖ **Ejecutar Fase 1 YA** ‚Üí Validaci√≥n r√°pida (2 horas)
2. ‚úÖ **Si exitosa, Fase 2** ‚Üí Mejoras cr√≠ticas (1 d√≠a)
3. ‚è∏Ô∏è **Fase 3 solo si necesario** ‚Üí Basado en feedback real

**NO hay riesgo** de romper funcionalidad SGR existente si se sigue este plan.

---

## 11. ARQUITECTURAS DE SEPARACI√ìN: COLECCIONES vs FILTROS

### CONTEXTO

El usuario requiere **separaci√≥n TOTAL** de embeddings por √°rea, de modo que al seleccionar un √°rea (SGR, IA, etc.) SOLO se consulte esa √°rea, sin posibilidad de contaminaci√≥n cruzada.

Existen **DOS arquitecturas** posibles:

---

### 11.1 OPCI√ìN A: Una Colecci√≥n + Filtros de Metadata (ACTUAL)

#### Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         QDRANT: Colecci√≥n "normativa_sgr"           ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Chunk 1: {vector, metadata: {area: "sgr"}}        ‚îÇ
‚îÇ  Chunk 2: {vector, metadata: {area: "sgr"}}        ‚îÇ
‚îÇ  Chunk 3: {vector, metadata: {area: "ia"}}         ‚îÇ
‚îÇ  Chunk 4: {vector, metadata: {area: "ia"}}         ‚îÇ
‚îÇ  Chunk 500: {vector, metadata: {area: "sgr"}}      ‚îÇ
‚îÇ  Chunk 501: {vector, metadata: {area: "ia"}}       ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
        Query con filtro: {area: "sgr"}
                        ‚Üì
    Solo retorna chunks con area="sgr"
```

#### Implementaci√≥n Actual

```python
# src/config.py (l√≠nea 39)
collection_name: str = "normativa_sgr"  # UNA sola colecci√≥n

# src/retrieval/vector_search.py (l√≠nea 66-79)
def search(
    self,
    query: str,
    top_k: int = None,
    documento_id: Optional[str] = None,
    articulo: Optional[str] = None,
    # ... otros filtros ...
    # ‚ùå NO EXISTE: area: Optional[str] = None
):
    # B√∫squeda en self.collection_name = "normativa_sgr"
    # Con filtros de metadata
```

#### Ventajas ‚úÖ

1. **Simplicidad arquitect√≥nica**
   - Un solo cliente Qdrant
   - Una sola conexi√≥n
   - C√≥digo m√°s simple

2. **Flexibilidad de consultas**
   - Puedes buscar EN M√öLTIPLES √ÅREAS a la vez
   - Queries cross-domain: "Compara regulaci√≥n SGR vs regulaci√≥n IA"
   - Filtros combinados: `{area: ["sgr", "ia"], capitulo: "5"}`

3. **Gesti√≥n de datos**
   - Backup m√°s simple (una colecci√≥n)
   - Migraciones m√°s sencillas
   - Monitoreo centralizado

4. **Performance**
   - Menor overhead (no switching entre colecciones)
   - Menor uso de memoria (un √≠ndice)

5. **Costos**
   - Sin duplicaci√≥n de infraestructura
   - Menor uso de disco

#### Desventajas ‚ùå

1. **Posibilidad de "filtrado incorrecto"**
   - Si el c√≥digo NO pasa filtro `area`, retorna TODOS los chunks
   - Riesgo de mezclar resultados si hay bug

2. **Performance con dataset grande**
   - B√∫squeda debe escanear TODA la colecci√≥n y filtrar
   - Impacto: +10-20ms de latencia con 10k+ chunks totales
   - Mitigable con √≠ndices de metadata (Qdrant los soporta)

3. **Escalabilidad conceptual**
   - Si agregas 10 √°reas nuevas, la colecci√≥n crece linealmente
   - Dificulta an√°lisis por √°rea (requiere queries agregadas)

#### Cambios Necesarios (M√≠nimos)

```python
# 1. Agregar campo "area" en metadata (document_hierarchy_processor.py)
chunk = {
    "area": metadata.get("area", "general"),  # NUEVO CAMPO
    # ... resto de campos ...
}

# 2. Extender search() para aceptar filtro area (vector_search.py)
def search(
    self,
    query: str,
    area: Optional[str] = None,  # NUEVO PAR√ÅMETRO
    # ... otros par√°metros ...
):
    # Construir filtro
    filter_conditions = []
    if area:
        filter_conditions.append(
            FieldCondition(key="area", match=MatchValue(value=area))
        )
    # ... aplicar filtro a b√∫squeda ...

# 3. UI: Dropdown de √°rea (streamlit_app.py)
area_filter = st.selectbox("√Årea", ["SGR", "Inteligencia Artificial", "Todas"])
if area_filter != "Todas":
    chunks = vector_search.search(query, area=area_filter.lower())
```

**Esfuerzo:** ~4 horas

---

### 11.2 OPCI√ìN B: Colecciones Separadas por √Årea (NUEVA)

#### Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  QDRANT: Colecci√≥n "sgr"     ‚îÇ     ‚îÇ  QDRANT: Colecci√≥n "ia"      ‚îÇ
‚îÇ                              ‚îÇ     ‚îÇ                              ‚îÇ
‚îÇ  Chunk 1: {vector, metadata} ‚îÇ     ‚îÇ  Chunk 1: {vector, metadata} ‚îÇ
‚îÇ  Chunk 2: {vector, metadata} ‚îÇ     ‚îÇ  Chunk 2: {vector, metadata} ‚îÇ
‚îÇ  ...                         ‚îÇ     ‚îÇ  ...                         ‚îÇ
‚îÇ  Chunk 500: {...}            ‚îÇ     ‚îÇ  Chunk 600: {...}            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì                                    ‚Üì
   Usuario selecciona "SGR"          Usuario selecciona "IA"
           ‚Üì                                    ‚Üì
    B√∫squeda SOLO en "sgr"             B√∫squeda SOLO en "ia"
```

#### Separaci√≥n Garantizada

```python
# IMPOSIBLE mezclar √°reas:
# - Cada √°rea = colecci√≥n f√≠sica separada
# - Vector search ejecuta en UNA colecci√≥n a la vez
# - Sin filtros ‚Üí Sin riesgo de bugs de filtrado
```

#### Ventajas ‚úÖ

1. **Separaci√≥n TOTAL garantizada** ‚≠ê
   - Imposible mezclar resultados por error
   - No depende de filtros (que pueden fallar)
   - Aislamiento completo de datos

2. **Performance √≥ptima por √°rea**
   - B√∫squeda SOLO escanea chunks del √°rea
   - Latencia: ~50% m√°s r√°pida que con filtros (con datasets grandes)
   - √çndices optimizados por dominio

3. **Gesti√≥n independiente**
   - Puedes borrar/recrear √°rea IA sin tocar SGR
   - Backups selectivos por √°rea
   - Configuraci√≥n diferenciada:
     ```python
     sgr_collection: {distance: "Cosine", quantization: True}
     ia_collection: {distance: "Dot", quantization: False}
     ```

4. **Escalabilidad clara**
   - Nueva √°rea = nueva colecci√≥n (sin afectar otras)
   - Crecimiento modular
   - Monitoreo por √°rea (tama√±o, queries, latencia)

5. **Seguridad/Permisos**
   - Futuro: Permisos por colecci√≥n
   - ACLs diferenciados (usuario A ‚Üí solo "sgr", usuario B ‚Üí solo "ia")

#### Desventajas ‚ùå

1. **Complejidad arquitect√≥nica**
   - M√∫ltiples clientes Qdrant (o routing manual)
   - C√≥digo m√°s complejo (mapeo area ‚Üí collection_name)
   - Mayor superficie de error

2. **Queries cross-domain imposibles**
   - NO puedes buscar en m√∫ltiples √°reas simult√°neamente
   - "Compara regulaci√≥n SGR vs IA" requiere:
     - 2 b√∫squedas separadas
     - Merge manual de resultados
     - Re-ranking cross-collection

3. **Gesti√≥n de datos m√°s compleja**
   - Backups de N colecciones
   - Migraciones por cada colecci√≥n
   - Monitoreo de m√∫ltiples √≠ndices

4. **Overhead de recursos**
   - N √≠ndices en memoria (vs 1)
   - Mayor uso de disco (cada colecci√≥n tiene overhead)
   - Impacto: ~5-10% m√°s memoria por colecci√≥n adicional

5. **Configuraci√≥n duplicada**
   - Mismo vector_size, distance, etc. para todas
   - Cambios de config requieren actualizar N colecciones

#### Cambios Necesarios (Moderados)

##### A. Configuraci√≥n Multi-Colecci√≥n

```python
# src/config.py - NUEVO
class QdrantConfig(BaseModel):
    # ... campos actuales ...

    # OPCI√ìN 1: Mapeo expl√≠cito
    collections: Dict[str, str] = Field(default_factory=lambda: {
        "sgr": "normativa_sgr",
        "inteligencia_artificial": "normativa_ia",
        "general": "normativa_general"
    })

    # OPCI√ìN 2: Prefijo autom√°tico
    collection_prefix: str = "normativa_"
    # Genera: "normativa_sgr", "normativa_ia", etc.

    @property
    def get_collection_name(self, area: str) -> str:
        """Obtiene nombre de colecci√≥n para un √°rea."""
        return self.collections.get(area, "normativa_general")
```

##### B. Vectorizer Multi-Colecci√≥n

```python
# src/ingest/vectorizer.py - MODIFICADO

class Vectorizer:
    def __init__(self, area: str = "general", use_hybrid_search: bool = True):
        # ... inicializaci√≥n actual ...

        self.area = area  # NUEVO: √°rea objetivo
        self.collection_name = config.qdrant.get_collection_name(area)
        logger.info(f"Vectorizer para √°rea '{area}' ‚Üí colecci√≥n '{self.collection_name}'")

    def create_collection(self, recreate: bool = False) -> None:
        """
        Crea colecci√≥n espec√≠fica del √°rea.
        """
        # ... l√≥gica actual, usa self.collection_name ...

    def load_chunks(self, chunks: List[Dict]) -> int:
        """
        Carga chunks EN LA COLECCI√ìN DEL √ÅREA.
        """
        # ... l√≥gica actual, usa self.collection_name ...
```

##### C. VectorSearch Multi-Colecci√≥n

```python
# src/retrieval/vector_search.py - MODIFICADO

class VectorSearch:
    def __init__(
        self,
        area: str = "general",  # NUEVO PAR√ÅMETRO
        qdrant_client: Optional[QdrantClient] = None,
        use_hybrid_search: bool = True
    ):
        # ... inicializaci√≥n actual ...

        self.area = area
        self.collection_name = config.qdrant.get_collection_name(area)
        logger.info(f"VectorSearch para √°rea '{area}' ‚Üí colecci√≥n '{self.collection_name}'")

    def search(
        self,
        query: str,
        top_k: int = None,
        # ... otros par√°metros (SIN area, ya definido en __init__) ...
    ) -> List[Dict]:
        """
        B√∫squeda EN LA COLECCI√ìN DEL √ÅREA.
        """
        # ... l√≥gica actual, usa self.collection_name ...
```

##### D. Pipeline Multi-√Årea

```python
# src/pipeline.py - MODIFICADO

class RAGPipeline:
    def __init__(self, area: str = "sgr"):  # NUEVO PAR√ÅMETRO
        self.area = area

        # Inicializar componentes con √°rea espec√≠fica
        self.vector_search = VectorSearch(area=area)
        self.multihop_retriever = MultihopRetriever(
            vector_search=self.vector_search,
            area=area
        )
        # ... resto de componentes ...
```

##### E. UI con Selector de √Årea

```python
# app/streamlit_app.py - MODIFICADO

st.title("Sistema RAG Multi-√Årea")

# Selector de √°rea (DETERMINA COLECCI√ìN)
area = st.sidebar.selectbox(
    "Seleccionar √Årea de Consulta",
    options=["sgr", "inteligencia_artificial", "general"],
    format_func=lambda x: {
        "sgr": "Sistema General de Regal√≠as",
        "inteligencia_artificial": "Inteligencia Artificial",
        "general": "General"
    }[x]
)

# Inicializar pipeline CON √ÅREA SELECCIONADA
@st.cache_resource
def get_pipeline(area: str):
    return RAGPipeline(area=area)

pipeline = get_pipeline(area)

# Query ejecuta SOLO en colecci√≥n del √°rea
query = st.text_input("Pregunta:")
if query:
    result = pipeline.query(query)  # Busca en collection_name del √°rea
    st.write(result["respuesta"])
```

##### F. Script de Ingesti√≥n Multi-√Årea

```python
# scripts/01_ingest_pdfs.py - MODIFICADO

import argparse

parser = argparse.ArgumentParser()
parser.add_argument("--area", required=True, choices=["sgr", "ia", "general"])
parser.add_argument("--data-dir", required=True)
args = parser.parse_args()

# Procesar documentos para √ÅREA ESPEC√çFICA
vectorizer = Vectorizer(area=args.area)
vectorizer.create_collection(recreate=False)  # NO borra otras colecciones

# Ejemplo de uso:
# python scripts/01_ingest_pdfs.py --area sgr --data-dir data/normativa_sgr
# python scripts/01_ingest_pdfs.py --area ia --data-dir data_topic_IA
```

**Esfuerzo:** ~12-16 horas (3x m√°s complejo que Opci√≥n A)

---

### 11.3 COMPARACI√ìN T√âCNICA DETALLADA

| Aspecto | Opci√≥n A (Filtros) | Opci√≥n B (Colecciones) |
|---------|-------------------|------------------------|
| **Separaci√≥n de datos** | ‚ö†Ô∏è L√≥gica (via filtros) | ‚úÖ F√≠sica (colecciones separadas) |
| **Riesgo de mezcla** | ‚ö†Ô∏è Medio (bugs en filtros) | ‚úÖ Nulo (imposible mezclar) |
| **Performance b√∫squeda** | ‚ö†Ô∏è Buena (con √≠ndices metadata) | ‚úÖ Excelente (b√∫squeda m√°s peque√±a) |
| **Latencia estimada** | ~100-150ms (10k chunks) | ~50-80ms por √°rea |
| **Memoria RAM** | ‚úÖ 1x (un √≠ndice) | ‚ö†Ô∏è 1.5-2x (N √≠ndices) |
| **Disco** | ‚úÖ √ìptimo | ‚ö†Ô∏è +10% overhead por colecci√≥n |
| **Complejidad c√≥digo** | ‚úÖ Simple (4 horas) | ‚ö†Ô∏è Moderada (16 horas) |
| **Queries cross-domain** | ‚úÖ Nativas | ‚ùå Requiere merge manual |
| **Escalabilidad** | ‚ö†Ô∏è Lineal (degrada con N √°reas) | ‚úÖ Modular (cada √°rea aislada) |
| **Gesti√≥n backups** | ‚úÖ Un archivo | ‚ö†Ô∏è N archivos |
| **Rollback cambios** | ‚ö†Ô∏è Afecta toda la colecci√≥n | ‚úÖ Por √°rea (sin afectar otras) |
| **Permisos futuros** | ‚ö†Ô∏è Requiere filtros de app | ‚úÖ ACLs nativos de Qdrant |
| **Testing** | ‚úÖ Un entorno de prueba | ‚ö†Ô∏è N entornos (uno por √°rea) |
| **Mantenimiento** | ‚úÖ Centralizado | ‚ö†Ô∏è Distribuido |

---

### 11.4 CASOS DE USO Y RECOMENDACI√ìN

#### Cu√°ndo usar OPCI√ìN A (Filtros)

‚úÖ **Recomendado si:**
- Tienes 2-5 √°reas totales
- Necesitas queries cross-domain frecuentes
- Priorizas simplicidad arquitect√≥nica
- Dataset total < 50k chunks
- Equipo peque√±o (mantenimiento simple)

**Ejemplo de uso:**
```python
# B√∫squeda multi-√°rea en una query
chunks = vector_search.search(
    query="regulaci√≥n de IA en Colombia",
    area=None  # Busca en TODAS las √°reas
)
# Retorna chunks de SGR + IA que mencionen "regulaci√≥n"
```

#### Cu√°ndo usar OPCI√ìN B (Colecciones)

‚úÖ **Recomendado si:**
- Requieres separaci√≥n TOTAL garantizada (compliance, legal)
- Tienes 5+ √°reas diferentes
- Cada √°rea tiene >10k chunks
- Necesitas permisos diferenciados por √°rea
- Priorizas performance sobre simplicidad
- Queries cross-domain son raras (<5% de casos)

**Ejemplo de uso:**
```python
# Usuario selecciona √°rea en UI
area_seleccionada = "inteligencia_artificial"

# Pipeline busca SOLO en esa colecci√≥n
pipeline = RAGPipeline(area=area_seleccionada)
chunks = pipeline.query("¬øQu√© es el EU AI Act?")
# IMPOSIBLE que retorne chunks de SGR
```

---

### 11.5 RECOMENDACI√ìN PARA TU CASO

#### An√°lisis de Requerimientos

```yaml
Tu contexto:
  - √Åreas actuales: 2 (SGR, IA)
  - √Åreas futuras: Posiblemente 2-3 m√°s
  - Dataset SGR: ~500 chunks
  - Dataset IA: ~600-1500 chunks (seg√∫n docs procesados)
  - Total: ~2000 chunks
  - Queries cross-domain: Probablemente bajas (<10%)
  - Prioridad: Evitar confusi√≥n entre √°reas ‚≠ê
  - Equipo: 1 persona (simplicidad importante)
```

#### RECOMENDACI√ìN: **OPCI√ìN A (Filtros) con mejoras** ‚≠ê

**Justificaci√≥n:**

1. **Dataset peque√±o-mediano** (2k chunks)
   - No hay degradaci√≥n de performance
   - Filtros de metadata son suficientemente r√°pidos

2. **Pocas √°reas** (2-3)
   - No justifica complejidad de multi-colecci√≥n
   - Gesti√≥n simple

3. **Desarrollo r√°pido**
   - 4 horas vs 16 horas
   - Menor superficie de error

4. **Suficientemente seguro con mejoras:**

```python
# MEJORA 1: Validaci√≥n obligatoria de √°rea
def search(self, query: str, area: str):  # area SIN Optional (requerido)
    if area not in ["sgr", "ia", "general"]:
        raise ValueError(f"√Årea inv√°lida: {area}")
    # ... b√∫squeda con filtro obligatorio ...

# MEJORA 2: UI con √°rea pre-seleccionada (no opcional)
area = st.sidebar.selectbox("√Årea", ["SGR", "IA"])  # SIN opci√≥n "Todas"

# MEJORA 3: Logging de √°rea en cada query
logger.info(f"Query en √°rea '{area}': {query}")

# MEJORA 4: M√©tricas por √°rea
# Trackear: queries_por_area = {"sgr": 150, "ia": 50}
```

**Con estas mejoras:**
- ‚úÖ Separaci√≥n pr√°cticamente garantizada (√°rea siempre especificada)
- ‚úÖ Simple de mantener
- ‚úÖ Performance excelente
- ‚úÖ Espacio para crecer a Opci√≥n B si es necesario (migraci√≥n factible)

---

### 11.6 PLAN DE IMPLEMENTACI√ìN (Opci√≥n A Mejorada)

#### Fase 1: Cambios M√≠nimos (4 horas)

```python
# 1. Agregar campo "area" en metadata
# Archivo: src/ingest/document_hierarchy_processor.py
chunk["area"] = metadata.get("area", "general")

# 2. Extender VectorSearch.search()
# Archivo: src/retrieval/vector_search.py
def search(self, query: str, area: str, top_k: int = None, ...):
    if area not in ["sgr", "inteligencia_artificial", "general"]:
        raise ValueError(f"√Årea inv√°lida: {area}")

    filter_conditions = [
        FieldCondition(key="area", match=MatchValue(value=area))
    ]
    # ... aplicar filtro ...

# 3. UI con selector obligatorio
# Archivo: app/streamlit_app.py
area = st.sidebar.selectbox(
    "√Årea de Consulta",
    options=["sgr", "inteligencia_artificial"],
    format_func=lambda x: AREA_NAMES[x]
)
# Pasar √°rea a pipeline
result = pipeline.query(query, area=area)

# 4. Script de ingesti√≥n con metadata
# Archivo: scripts/01_ingest_pdfs.py
metadata = {
    "area": "inteligencia_artificial",  # O "sgr" seg√∫n carpeta
    # ... resto de metadata ...
}
```

#### Fase 2: Validaciones y Logging (2 horas)

```python
# 1. Validaci√≥n de √°rea en ingesti√≥n
def validate_area(area: str):
    VALID_AREAS = ["sgr", "inteligencia_artificial", "general"]
    if area not in VALID_AREAS:
        raise ValueError(f"√Årea debe ser una de: {VALID_AREAS}")

# 2. Logging exhaustivo
logger.info(f"[√ÅREA:{area}] Query: {query}")
logger.info(f"[√ÅREA:{area}] Chunks encontrados: {len(chunks)}")

# 3. M√©tricas por √°rea
metrics = {
    "area": area,
    "query_count": queries_por_area.get(area, 0) + 1,
    "avg_latency": calculate_avg_latency(area)
}
```

#### Fase 3: Testing (2 horas)

```python
# Tests de separaci√≥n
def test_area_separation():
    # Crear chunks de prueba en ambas √°reas
    vectorizer.load_chunks([
        {"texto": "OCAD viabiliza proyectos", "area": "sgr"},
        {"texto": "EU AI Act regula IA", "area": "inteligencia_artificial"}
    ])

    # Buscar SOLO en SGR
    results_sgr = vector_search.search("OCAD", area="sgr")
    assert all(c["area"] == "sgr" for c in results_sgr)

    # Buscar SOLO en IA
    results_ia = vector_search.search("EU AI Act", area="inteligencia_artificial")
    assert all(c["area"] == "inteligencia_artificial" for c in results_ia)
```

**Total:** 8 horas (vs 16+ horas de Opci√≥n B)

---

### 11.7 MIGRACI√ìN FUTURA (Si necesitas Opci√≥n B)

Si en el futuro decides cambiar a colecciones separadas:

#### Estrategia de Migraci√≥n

```python
# 1. Exportar chunks por √°rea
sgr_chunks = export_chunks_by_area("normativa_sgr", area="sgr")
ia_chunks = export_chunks_by_area("normativa_sgr", area="inteligencia_artificial")

# 2. Crear nuevas colecciones
vectorizer_sgr = Vectorizer(area="sgr")
vectorizer_sgr.create_collection()
vectorizer_sgr.load_chunks(sgr_chunks)

vectorizer_ia = Vectorizer(area="inteligencia_artificial")
vectorizer_ia.create_collection()
vectorizer_ia.load_chunks(ia_chunks)

# 3. Validar integridad
assert count_chunks("normativa_sgr") == count_chunks("sgr") + count_chunks("ia")

# 4. Deprecar colecci√≥n antigua
qdrant_client.delete_collection("normativa_sgr")
```

**Esfuerzo de migraci√≥n:** ~8 horas (solo si realmente lo necesitas)

---

### 11.8 RESUMEN EJECUTIVO

#### Decisi√≥n Recomendada: **OPCI√ìN A con Mejoras** ‚≠ê

**Razones:**
1. ‚úÖ Dataset peque√±o (2k chunks) ‚Üí filtros son suficientes
2. ‚úÖ Pocas √°reas (2-3) ‚Üí complejidad no justificada
3. ‚úÖ Desarrollo 2x m√°s r√°pido (8h vs 16h)
4. ‚úÖ Migraci√≥n a Opci√≥n B es factible si creces
5. ‚úÖ Con validaciones estrictas, separaci√≥n es pr√°cticamente garantizada

**Implementaci√≥n:**
- Campo `area` obligatorio en metadata
- Filtro `area` obligatorio en b√∫squedas (no opcional)
- UI sin opci√≥n "Todas las √°reas" (fuerza selecci√≥n)
- Logging y m√©tricas por √°rea

**Resultado:**
- Separaci√≥n efectiva entre SGR e IA
- Sin complejidad arquitect√≥nica
- Espacio para evolucionar

---

**Fecha de an√°lisis:** 2025-11-11
**Pr√≥xima revisi√≥n:** Despu√©s de Fase 1
**Responsable:** Claude Code + Usuario
