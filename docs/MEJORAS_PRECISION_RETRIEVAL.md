# AnÃ¡lisis y Mejoras para PrecisiÃ³n de Retrieval

**Fecha:** 2025-11-12
**Contexto:** Prueba de 60 preguntas sobre documentos de IA
**Problema:** ~25% de preguntas (15/60) retornan "No encontrÃ© informaciÃ³n" a pesar de encontrar chunks

---

## ğŸ“Š ANÃLISIS DEL PROBLEMA

### Preguntas que Fallaron

#### CONPES Colombia (3/6 fallidas)
- âŒ "Â¿CuÃ¡l es el objetivo nÃºmero 1...?" â†’ Busca info especÃ­fica (objetivo numerado)
- âŒ "Â¿CuÃ¡l es el objetivo nÃºmero 4...?" â†’ Busca info especÃ­fica (objetivo numerado)
- âŒ "Â¿CuÃ¡l es el costo estimado...?" â†’ Busca dato numÃ©rico especÃ­fico

#### EU AI Act (4/6 fallidas)
- âŒ "Â¿CuÃ¡les son los niveles de riesgo...?" â†’ Lista especÃ­fica
- âŒ "Â¿QuÃ© sanciones econÃ³micas...?" â†’ Datos numÃ©ricos/legales
- âŒ "Â¿CuÃ¡les son prÃ¡cticas prohibidas...?" â†’ Lista especÃ­fica
- âŒ "Â¿QuÃ© obligaciones de transparencia...?" â†’ Requisitos especÃ­ficos

#### Facultad Caldas (1/6 fallida)
- âŒ "Â¿QuÃ© sucede si un estudiante beneficiario...?" â†’ Caso especÃ­fico

#### IEEE Ã‰tica (1/6 fallida)
- âŒ "Â¿QuÃ© indica sobre competencia de operadores...?" â†’ Aspecto especÃ­fico

#### Historia IA (2/6 fallidas)
- âŒ "Â¿QuÃ© aplicaciones actuales...?" â†’ Lista de ejemplos
- âŒ "Â¿CuÃ¡ndo resurgieron las redes neuronales...?" â†’ Fecha/evento especÃ­fico

#### Ametic (2/6 fallidas)
- âŒ "Â¿Ejemplos prÃ¡cticos de IA generativa...?" â†’ Lista de ejemplos
- âŒ "Â¿QuÃ© retos principales...?" â†’ Lista especÃ­fica

#### GuÃ­a Estudiantes (1/6 fallida)
- âŒ "Â¿Cambios positivos y negativos...?" â†’ ComparaciÃ³n/lista

#### UNESCO (1/6 fallida)
- âŒ "Â¿QuÃ© recomienda UNESCO para desarrollo Ã©tico...?" â†’ Recomendaciones especÃ­ficas

---

## ğŸ” PATRONES IDENTIFICADOS

### 1. **BÃºsquedas de InformaciÃ³n Muy EspecÃ­fica**
- NÃºmeros de objetivos ("objetivo nÃºmero 1", "objetivo nÃºmero 4")
- Datos numÃ©ricos exactos (costos, sanciones)
- Fechas especÃ­ficas ("en 1943", "a mediados de los 80")

**Problema:** El chunking puede separar el nÃºmero del contexto

### 2. **Listas y Enumeraciones**
- "Â¿CuÃ¡les son los niveles...?"
- "Â¿CuÃ¡les son las prÃ¡cticas prohibidas...?"
- "Â¿QuÃ© ejemplos...?"

**Problema:** La lista completa puede estar distribuida en mÃºltiples chunks

### 3. **InformaciÃ³n Contextual Profunda**
- Requiere contexto de varios pÃ¡rrafos
- InformaciÃ³n que estÃ¡ en subsecciones especÃ­ficas

**Problema:** El chunk relevante puede no tener suficiente contexto

---

## ğŸ’¡ MEJORAS PROPUESTAS (Priorizadas)

### ğŸ”´ CRÃTICAS (Implementar Ya)

#### 1. **Mejorar Query Enhancement para TÃ©rminos EspecÃ­ficos**
**UbicaciÃ³n:** `src/retrieval/query_enhancer.py`

```python
# AGREGAR: DetecciÃ³n de nÃºmeros y tÃ©rminos especÃ­ficos
def _enhance_specific_queries(self, query: str) -> Dict:
    """Detecta y expande consultas con tÃ©rminos muy especÃ­ficos."""

    enhancements = []

    # Detectar nÃºmeros de objetivos/artÃ­culos
    if re.search(r'(objetivo|artÃ­culo|secciÃ³n|capÃ­tulo)\s+(nÃºmero\s+)?(\d+)', query, re.I):
        match = re.search(r'(objetivo|artÃ­culo|secciÃ³n|capÃ­tulo)\s+(nÃºmero\s+)?(\d+)', query, re.I)
        tipo = match.group(1)
        numero = match.group(3)

        # Generar variaciones
        enhancements.extend([
            f"{tipo} {numero}",
            f"{tipo} nÃºmero {numero}",
            f"{numero}. {tipo}",
            f"{tipo.upper()} {numero}",
        ])

    # Detectar solicitudes de listas
    if re.search(r'(cuÃ¡les|quÃ©).*(niveles|tipos|ejemplos|prÃ¡cticas|requisitos)', query, re.I):
        enhancements.append("lista completa enumerar todos")

    # Detectar bÃºsqueda de datos numÃ©ricos
    if re.search(r'(costo|precio|sanciÃ³n|multa|cantidad|nÃºmero)', query, re.I):
        enhancements.append("datos numÃ©ricos cifras monto")

    return {
        "enhanced_query": query + " " + " ".join(enhancements),
        "expansions": enhancements
    }
```

**Impacto esperado:** +40% precisiÃ³n en preguntas especÃ­ficas

---

#### 2. **Aumentar top_k para Preguntas Complejas**
**UbicaciÃ³n:** `src/retrieval/query_enhancer.py`

```python
def get_retrieval_config(self, enhancement: Dict, default_top_k: int = 10) -> Dict:
    """Ajusta top_k dinÃ¡micamente segÃºn complejidad."""

    query_type = enhancement.get("query_type", "semantic")

    # NUEVO: Detectar preguntas que requieren mÃ¡s contexto
    if any(keyword in enhancement["original_query"].lower() for keyword in [
        "cuÃ¡les", "enumera", "lista", "todos", "ejemplos", "niveles"
    ]):
        # Buscar mÃ¡s chunks para listas y enumeraciones
        return {"top_k_retrieval": 20, "top_k_rerank": 10}

    if enhancement.get("has_specific_terms"):  # nÃºmeros, fechas, datos especÃ­ficos
        return {"top_k_retrieval": 15, "top_k_rerank": 8}

    # Config actual
    if query_type == "aggregation":
        return {"top_k_retrieval": 100, "top_k_rerank": 10}

    return {"top_k_retrieval": default_top_k, "top_k_rerank": 5}
```

**Impacto esperado:** +25% cobertura en listas y enumeraciones

---

#### 3. **Mejorar BM25 para BÃºsquedas Exactas**
**UbicaciÃ³n:** `src/retrieval/vector_search.py`

```python
def _hybrid_search(self, query_embedding, query_text, top_k, filters):
    """Ajusta pesos de BM25 vs vectorial segÃºn tipo de query."""

    # Detectar si la query tiene tÃ©rminos muy especÃ­ficos
    has_numbers = bool(re.search(r'\d+', query_text))
    has_quotes = '"' in query_text
    has_specific_terms = any(term in query_text.lower() for term in [
        'nÃºmero', 'artÃ­culo', 'secciÃ³n', 'costo', 'sanciÃ³n', 'objetivo'
    ])

    if has_numbers or has_quotes or has_specific_terms:
        # Dar mÃ¡s peso a BM25 (bÃºsqueda exacta)
        bm25_weight = 0.6  # En lugar de 0.5
        vector_weight = 0.4
        logger.debug(f"Query especÃ­fica detectada, aumentando peso BM25 a {bm25_weight}")
    else:
        # Pesos normales
        bm25_weight = 0.5
        vector_weight = 0.5

    # Ejecutar bÃºsquedas...
    dense_results = self._search_dense(query_embedding, top_k * 2, filters)
    sparse_results = self._search_sparse_bm25(query_text, top_k * 2, filters)

    # Fusion con pesos ajustados
    fused = self._reciprocal_rank_fusion(
        dense_results,
        sparse_results,
        top_k,
        weights=(vector_weight, bm25_weight)  # NUEVO: pesos variables
    )

    return fused
```

**Impacto esperado:** +30% precisiÃ³n en bÃºsquedas con nÃºmeros/tÃ©rminos exactos

---

### ğŸŸ¡ IMPORTANTES (Implementar Pronto)

#### 4. **Context Expansion MÃ¡s Agresivo**
**UbicaciÃ³n:** `src/retrieval/vector_search.py`

```python
def search_with_context(
    self,
    query: str,
    area: str,
    top_k: int = None,
    expand_context: bool = True,
    context_window: int = 1,  # NUEVO: configurable
    **kwargs
) -> List[Dict]:
    """Expande contexto con chunks adyacentes."""

    # Buscar chunks base
    base_chunks = self.search(query, area, top_k, **kwargs)

    if not expand_context:
        return base_chunks

    # MEJORADO: Expandir con ventana configurable
    expanded_chunks = []
    seen_ids = set()

    for chunk in base_chunks:
        # Agregar chunk base
        if chunk["chunk_id"] not in seen_ids:
            expanded_chunks.append(chunk)
            seen_ids.add(chunk["chunk_id"])

        # Expandir ANTES y DESPUÃ‰S con ventana
        for offset in range(-context_window, context_window + 1):
            if offset == 0:
                continue

            adjacent = self._get_adjacent_chunk(chunk, offset)
            if adjacent and adjacent["chunk_id"] not in seen_ids:
                adjacent["from_expansion"] = True
                adjacent["expansion_offset"] = offset
                expanded_chunks.append(adjacent)
                seen_ids.add(adjacent["chunk_id"])

    return expanded_chunks
```

**Uso:**
```python
# Para preguntas complejas, usar ventana mÃ¡s grande
chunks = vector_search.search_with_context(
    query="Â¿CuÃ¡les son todos los niveles de riesgo?",
    area="inteligencia_artificial",
    context_window=2  # Expandir 2 chunks antes y despuÃ©s
)
```

**Impacto esperado:** +20% informaciÃ³n completa en listas

---

#### 5. **Chunk Hierarchy-Aware Search**
**UbicaciÃ³n:** `src/retrieval/vector_search.py`

```python
def search_with_hierarchy(
    self,
    query: str,
    area: str,
    include_parent: bool = True,
    include_siblings: bool = False,
    **kwargs
) -> List[Dict]:
    """Incluye chunks relacionados jerÃ¡rquicamente."""

    base_chunks = self.search(query, area, **kwargs)

    enriched_chunks = []

    for chunk in base_chunks:
        enriched_chunks.append(chunk)

        # Incluir chunk padre (contexto superior)
        if include_parent and chunk.get("parent_id"):
            parent = self._get_chunk_by_id(chunk["parent_id"])
            if parent:
                parent["from_hierarchy"] = "parent"
                enriched_chunks.append(parent)

        # Incluir chunks hermanos (mismo nivel)
        if include_siblings and chunk.get("parent_id"):
            siblings = self._get_sibling_chunks(chunk)
            for sibling in siblings[:3]:  # MÃ¡ximo 3 hermanos
                sibling["from_hierarchy"] = "sibling"
                enriched_chunks.append(sibling)

    return enriched_chunks
```

**Impacto esperado:** +15% contexto jerÃ¡rquico

---

#### 6. **Multi-Query Retrieval**
**UbicaciÃ³n:** `src/retrieval/multi_query_retriever.py` (NUEVO)

```python
class MultiQueryRetriever:
    """Genera mÃºltiples variaciones de la query para mejor recall."""

    def generate_query_variations(self, query: str) -> List[str]:
        """Genera variaciones de la query."""

        variations = [query]  # Original

        # VariaciÃ³n 1: ReformulaciÃ³n
        prompt = f"""Genera 2 reformulaciones de esta pregunta manteniendo el mismo significado:

Pregunta original: {query}

Reformulaciones (una por lÃ­nea):"""

        response = self.llm_client.generate_simple(prompt)
        variations.extend([v.strip() for v in response.split('\n') if v.strip()])

        # VariaciÃ³n 2: TÃ©rminos clave
        keywords = self._extract_keywords(query)
        variations.append(" ".join(keywords))

        # VariaciÃ³n 3: Query expandida
        expanded = self.query_enhancer.enhance_query(query)
        variations.append(expanded["enhanced_query"])

        return variations[:5]  # MÃ¡ximo 5 variaciones

    def retrieve_multi_query(
        self,
        query: str,
        area: str,
        top_k_per_query: int = 10
    ) -> List[Dict]:
        """Busca con mÃºltiples variaciones y fusiona resultados."""

        variations = self.generate_query_variations(query)

        all_chunks = []
        for i, variant_query in enumerate(variations):
            logger.info(f"Searching with variant {i+1}: {variant_query[:60]}...")

            chunks = self.vector_search.search(
                variant_query,
                area,
                top_k=top_k_per_query
            )

            for chunk in chunks:
                chunk["query_variant"] = i
                all_chunks.append(chunk)

        # Fusionar y re-rankear
        unique_chunks = self._deduplicate_chunks(all_chunks)
        reranked = self.reranker.rerank(query, unique_chunks, top_k=top_k_per_query)

        return reranked
```

**Impacto esperado:** +35% recall en preguntas ambiguas

---

### ğŸŸ¢ OPCIONALES (Mejoras Futuras)

#### 7. **Chunking Adaptativo**
- Chunks mÃ¡s pequeÃ±os (400 tokens) para documentos con listas
- Chunks mÃ¡s grandes (1000 tokens) para narrativas
- Overlap mayor (150 tokens) en documentos estructurados

**Impacto esperado:** +10% precisiÃ³n global

#### 8. **HyDE con Plantillas EspecÃ­ficas**
- Plantilla para "objetivos numerados"
- Plantilla para "listas y enumeraciones"
- Plantilla para "datos numÃ©ricos"

**Impacto esperado:** +15% en preguntas con formato especÃ­fico

#### 9. **Post-processing de Respuestas**
- Validar si la respuesta contiene el tÃ©rmino buscado
- Si no, buscar en chunks expandidos
- Retry con query reformulada

**Impacto esperado:** +20% respuestas completas

---

## ğŸ“ˆ IMPACTO ESTIMADO TOTAL

| Mejora | Impacto | Esfuerzo | Prioridad |
|--------|---------|----------|-----------|
| Query Enhancement EspecÃ­fico | +40% | 2h | ğŸ”´ CrÃ­tica |
| Top-k DinÃ¡mico | +25% | 1h | ğŸ”´ CrÃ­tica |
| BM25 con Pesos Ajustables | +30% | 3h | ğŸ”´ CrÃ­tica |
| Context Expansion Agresivo | +20% | 2h | ğŸŸ¡ Importante |
| Hierarchy-Aware Search | +15% | 3h | ğŸŸ¡ Importante |
| Multi-Query Retrieval | +35% | 4h | ğŸŸ¡ Importante |
| Chunking Adaptativo | +10% | 8h | ğŸŸ¢ Opcional |
| HyDE Mejorado | +15% | 4h | ğŸŸ¢ Opcional |
| Post-processing | +20% | 3h | ğŸŸ¢ Opcional |

**Con las 3 mejoras crÃ­ticas:** 75% â†’ **95% precisiÃ³n** (estimado)
**Con todas las mejoras:** 75% â†’ **98% precisiÃ³n** (estimado)

---

## ğŸ¯ PLAN DE IMPLEMENTACIÃ“N

### Fase 1: Quick Wins (1 semana)
1. âœ… Query Enhancement para tÃ©rminos especÃ­ficos
2. âœ… Top-k dinÃ¡mico
3. âœ… BM25 con pesos ajustables

**Resultado esperado:** 75% â†’ 90% precisiÃ³n

### Fase 2: Mejoras Importantes (2 semanas)
4. âœ… Context expansion agresivo
5. âœ… Hierarchy-aware search
6. âœ… Multi-query retrieval

**Resultado esperado:** 90% â†’ 95% precisiÃ³n

### Fase 3: Optimizaciones (1 mes)
7. âœ… Chunking adaptativo
8. âœ… HyDE mejorado
9. âœ… Post-processing

**Resultado esperado:** 95% â†’ 98% precisiÃ³n

---

## ğŸ§ª TESTING

### Script de ValidaciÃ³n
Crear `scripts/test_precision_improvements.py`:

```python
# Probar SOLO las 15 preguntas que fallaron
FAILED_QUESTIONS = [
    "Â¿CuÃ¡l es el objetivo nÃºmero 1 de la polÃ­tica nacional de inteligencia artificial en Colombia?",
    "Â¿CuÃ¡l es el objetivo nÃºmero 4 de la polÃ­tica nacional de inteligencia artificial en Colombia?",
    # ... resto de preguntas fallidas
]

# Ejecutar con configuraciÃ³n baseline
results_baseline = test_questions(FAILED_QUESTIONS, config="baseline")

# Ejecutar con mejoras
results_improved = test_questions(FAILED_QUESTIONS, config="improved")

# Comparar
compare_results(results_baseline, results_improved)
```

### MÃ©tricas a Medir
- **Precision@5**: Â¿Los top-5 chunks contienen la respuesta?
- **MRR (Mean Reciprocal Rank)**: Â¿En quÃ© posiciÃ³n estÃ¡ el chunk correcto?
- **Answer Quality**: Â¿La respuesta final es correcta?
- **Cost**: Â¿CuÃ¡nto costÃ³ por pregunta?

---

## ğŸ“š REFERENCIAS

- Documento original de pruebas: `test_results_ia_questions.json`
- Output completo: `test_output.log`
- Preguntas fuente: `Preguntas.pdf`

---

**Autor:** Claude Code
**Fecha:** 2025-11-12
**VersiÃ³n:** 1.0
