# ğŸ” AnÃ¡lisis Profundo: Problemas de ExtracciÃ³n y EstructuraciÃ³n de PDFs

## ğŸ“Š Estado Actual de la ExtracciÃ³n

### âœ… Lo que SÃ funciona

1. **DetecciÃ³n de documentos legales**: 11 tÃ­tulos, 19 capÃ­tulos, 345 artÃ­culos
2. **DetecciÃ³n de documentos tÃ©cnicos**: 53 secciones, 158 subsecciones, 279 sub-subsecciones
3. **Chunking por artÃ­culos**: Cada artÃ­culo se convierte en un chunk con metadata de `capitulo` y `titulo`

### âŒ Problemas CrÃ­ticos Identificados

## 1. **ANEXOS NO SE INDEXAN CORRECTAMENTE**

### El Problema

Los anexos se **detectan** en la extracciÃ³n (lÃ­nea 185-190 del extractor):
```python
if match := self.common_patterns["anexo"].search(line):
    structure["anexos"].append({
        "numero": match.group(1),
        "texto": line.strip(),
        "line_index": i,
    })
```

Pero **NO se usan** en el chunking. El chunker SOLO procesa:
- Para documentos legales: `articulos` (lÃ­nea 79-86 del chunker)
- Para documentos tÃ©cnicos: `secciones` y `subsecciones`
- **Los anexos nunca se convierten en chunks**

### Ejemplo del Problema

```
User: "Dame informaciÃ³n del Anexo 8 del acuerdo Ãºnico"
System: "No encontrÃ© informaciÃ³n..."
```

**Â¿Por quÃ©?** Porque el Anexo 8 nunca fue indexado. Los anexos estÃ¡n en el texto del PDF pero no en Qdrant.

---

## 2. **JERARQUÃA INCOMPLETA EN LOS CHUNKS**

### El Problema

Los chunks de artÃ­culos sÃ­ tienen `capitulo` y `titulo`, pero:

**FALTA informaciÃ³n jerÃ¡rquica del nombre/descripciÃ³n:**
```python
chunk = {
    "capitulo": "2",        # âœ… Tiene el nÃºmero
    "titulo": "4",          # âœ… Tiene el nÃºmero
    "capitulo_nombre": ???  # âŒ NO EXISTE - Â¿CuÃ¡l es el nombre del capÃ­tulo?
    "titulo_nombre": ???    # âŒ NO EXISTE - Â¿CuÃ¡l es el nombre del tÃ­tulo?
}
```

### Impacto

Cuando el LLM genera la respuesta, no puede decir:
> "El CapÃ­tulo 2 - Proyectos de InversiÃ³n trata sobre..."

Solo puede decir:
> "El CapÃ­tulo 2 trata sobre..."

**PÃ©rdida de contexto semÃ¡ntico importante.**

---

## 3. **CHUNKS DEMASIADO LARGOS (9K-13K TOKENS)**

### El Problema

SegÃºn los logs:
```
WARNING | Chunk 399: Truncating from 11956 to 8191 tokens
WARNING | Chunk 544: Truncating from 12477 to 8191 tokens
WARNING | Chunk 551: Truncating from 13219 to 8191 tokens
```

Algunos chunks tienen **mÃ¡s de 13,000 tokens** (~52,000 caracteres).

### Â¿Por quÃ©?

El chunker usa **artÃ­culos completos** como chunks. Si un artÃ­culo es muy largo (tiene muchos parÃ¡grafos, incisos, tablas), el chunk es gigante.

### Impacto

1. **PÃ©rdida de informaciÃ³n**: Se truncan a 8191 tokens, perdiendo contenido
2. **Mala precisiÃ³n de bÃºsqueda**: Chunks muy grandes son menos especÃ­ficos
3. **Contexto difuso**: El LLM recibe bloques enormes difÃ­ciles de procesar

---

## 4. **FALTA DETECCIÃ“N DE ELEMENTOS JERÃRQUICOS MENORES**

### Elementos NO Detectados

El extractor NO detecta:
- **Incisos** (numerales dentro de artÃ­culos: "1.", "2.", "3.")
- **Literales** (letras dentro de artÃ­culos: "a)", "b)", "c)")
- **Tablas** (contenido tabular importante)
- **Numerales romanos en contextos anidados**

### Ejemplo Real

```
ARTÃCULO 4.5.1.2 Variables susceptibles de ajuste

Los ajustes procederÃ¡n cuando:
1. Existan modificaciones en el alcance del proyecto
2. Se requiera actualizaciÃ³n de precios
3. Cambios en la normativa aplicable
   a) Normativa nacional
   b) Normativa regional
   c) Normativa local
```

**Actualmente**: Todo esto va en UN solo chunk gigante

**DeberÃ­a**:
- Chunk principal con el artÃ­culo
- Chunks secundarios para cada numeral (vinculados al artÃ­culo padre)
- Chunks terciarios para cada literal (vinculados al numeral padre)

---

## 5. **CHUNKING POR ARTÃCULOS ES INFLEXIBLE**

### El Problema Conceptual

La estrategia actual es: **1 artÃ­culo = 1 chunk**

Esto falla cuando:
1. âœ… ArtÃ­culos cortos (~100 tokens): Funciona bien
2. âŒ ArtÃ­culos medianos (~1000 tokens): Pierde granularidad
3. âŒ ArtÃ­culos largos (>5000 tokens): Se truncan, pierden informaciÃ³n

### Ejemplo de Fallo

**ArtÃ­culo largo sobre "Requisitos de viabilidad":**
- Tiene 15 requisitos enumerados
- Usuario pregunta: "Â¿CuÃ¡l es el requisito 7?"
- Sistema recupera chunk del artÃ­culo completo (8191 tokens truncado)
- LLM debe buscar el requisito 7 en un chunk gigante
- Puede no encontrarlo si fue truncado

**Mejor enfoque:**
- Chunk padre: Intro del artÃ­culo
- 15 chunks hijos: Uno por cada requisito
- Query enhancement detecta "requisito 7" y filtra

---

## 6. **ANEXOS NECESITAN TRATAMIENTO ESPECIAL**

### CaracterÃ­sticas Ãšnicas de los Anexos

1. **Contenido muy diferente**: Tablas, formularios, listas, diagramas
2. **TamaÃ±o variable**: Desde 1 pÃ¡gina hasta 50+ pÃ¡ginas
3. **Referencias cruzadas**: "Ver Anexo X" desde artÃ­culos
4. **MÃºltiples formatos**: Texto, tablas, imÃ¡genes

### Problema Actual

Los anexos se detectan pero:
- âŒ No se indexan como chunks
- âŒ No se vinculan a los artÃ­culos que los mencionan
- âŒ No se procesan segÃºn su contenido (tabla vs texto vs formulario)

---

## 7. **FALTA GRAFO DE RELACIONES**

### Lo que NO existe actualmente

No hay un grafo real de relaciones entre elementos:

```
Documento
  â”œâ”€ TÃ­tulo 1
  â”‚   â”œâ”€ CapÃ­tulo 1
  â”‚   â”‚   â”œâ”€ ArtÃ­culo 1.1.1
  â”‚   â”‚   â”‚   â”œâ”€ ParÃ¡grafo 1
  â”‚   â”‚   â”‚   â””â”€ ParÃ¡grafo 2
  â”‚   â”‚   â””â”€ ArtÃ­culo 1.1.2
  â”‚   â””â”€ CapÃ­tulo 2
  â””â”€ Anexos
      â”œâ”€ Anexo 1
      â””â”€ Anexo 2
```

**Actualmente solo hay:**
- Chunks planos con metadata `capitulo=2, titulo=1`
- NO hay relaciones explÃ­citas padre-hijo
- NO hay navegaciÃ³n jerÃ¡rquica

### Impacto

No se puede hacer queries como:
- "Dame todos los artÃ­culos del CapÃ­tulo 2"
- "Â¿QuÃ© parÃ¡grafos tiene el ArtÃ­culo 4.5.1?"
- "Muestra la jerarquÃ­a completa del TÃ­tulo 3"

---

## ğŸ¯ SOLUCIONES RECOMENDADAS

### Prioridad 1: ANEXOS (CrÃ­tico - bloquea queries actuales)

**Modificar el chunker para procesar anexos:**

```python
def _chunk_legal_document(self, content, structure, metadata):
    chunks = []

    # 1. Chunk articulos (ya existe)
    chunks.extend(self._chunk_articulos(...))

    # 2. Chunk anexos (NUEVO)
    chunks.extend(self._chunk_anexos(content, structure, metadata))

    return chunks

def _chunk_anexos(self, content, structure, metadata):
    chunks = []
    lines = content.split("\n")
    anexos = structure["anexos"]

    for i, anexo in enumerate(anexos):
        start_line = anexo["line_index"]
        # El anexo va desde su inicio hasta el prÃ³ximo anexo o fin de documento
        end_line = (
            anexos[i + 1]["line_index"]
            if i + 1 < len(anexos)
            else len(lines)
        )

        anexo_text = "\n".join(lines[start_line:end_line]).strip()

        # Si el anexo es muy largo, dividirlo
        if self._count_tokens(anexo_text) > self.chunk_size:
            sub_chunks = self._split_long_text(
                anexo_text,
                metadata=metadata,
                anexo_numero=anexo["numero"],
                doc_type="legal"
            )
            chunks.extend(sub_chunks)
        else:
            chunk = self._create_chunk(
                text=anexo_text,
                metadata=metadata,
                anexo_numero=anexo["numero"],
                doc_type="legal"
            )
            chunks.append(chunk)

    return chunks
```

**Actualizar schema de chunks:**
```python
chunk = {
    # ... campos existentes ...
    "anexo_numero": "8",  # NUEVO
    "es_anexo": True,     # NUEVO
}
```

**Actualizar query enhancement:**
```python
# Detectar "Anexo 8", "anexo VIII"
"anexo": re.compile(
    r"anexo\s+(\d+|[IVXLCDM]+)",
    re.IGNORECASE
)
```

---

### Prioridad 2: NOMBRES DE CAPÃTULOS/TÃTULOS (Mejora UX)

**Guardar nombres junto con nÃºmeros:**

```python
def _chunk_legal_document(self, content, structure, metadata):
    # ... cÃ³digo existente ...

    # Extraer nombres de tÃ­tulos y capÃ­tulos
    titulo_nombres = self._extract_nombres(structure["titulos"])
    capitulo_nombres = self._extract_nombres(structure["capitulos"])

    # Al crear chunk
    chunk = self._create_chunk(
        text=article_text,
        metadata=metadata,
        articulo=articulo["numero"],
        titulo=current_titulo,
        titulo_nombre=titulo_nombres.get(current_titulo),  # NUEVO
        capitulo=current_capitulo,
        capitulo_nombre=capitulo_nombres.get(current_capitulo),  # NUEVO
    )

def _extract_nombres(self, elements: List[Dict]) -> Dict[str, str]:
    """Extrae nombres de elementos jerÃ¡rquicos."""
    nombres = {}
    for elem in elements:
        # "TÃTULO 4 PROYECTOS DE INVERSIÃ“N"
        # -> numero="4", nombre="PROYECTOS DE INVERSIÃ“N"
        numero = elem["numero"]
        texto_completo = elem["texto"]

        # Remover el prefijo "TÃTULO 4" para dejar solo el nombre
        nombre = re.sub(
            r"^(T[ÃI]TULO|CAP[ÃI]TULO)\s+\d+\s*:?\s*",
            "",
            texto_completo,
            flags=re.IGNORECASE
        ).strip()

        nombres[numero] = nombre

    return nombres
```

---

### Prioridad 3: CHUNKING INTELIGENTE (Performance + PrecisiÃ³n)

**Estrategia multi-nivel:**

```python
def _chunk_articulo_inteligente(self, article_text, articulo_numero, metadata, ...):
    """Chunking adaptativo segÃºn tamaÃ±o y estructura del artÃ­culo."""

    token_count = self._count_tokens(article_text)

    if token_count <= 500:
        # ArtÃ­culo corto: 1 chunk completo
        return [self._create_chunk(text=article_text, ...)]

    elif token_count <= 2000:
        # ArtÃ­culo mediano: dividir por parÃ¡grafos si existen
        if self._tiene_paragrafos(article_text):
            return self._chunk_por_paragrafos(article_text, ...)
        else:
            return [self._create_chunk(text=article_text, ...)]

    else:
        # ArtÃ­culo largo: chunking jerÃ¡rquico agresivo
        return self._chunk_jerarquico(
            article_text,
            max_chunk_size=800,  # Chunks mÃ¡s pequeÃ±os
            overlap=100,         # Mayor overlap para coherencia
            ...
        )
```

---

### Prioridad 4: DETECCIÃ“N DE INCISOS Y LITERALES (Granularidad)

```python
# Agregar patrones
self.legal_patterns = {
    # ... existentes ...
    "inciso": re.compile(r"^(\d+)\.\s+", re.MULTILINE),
    "literal": re.compile(r"^([a-z])\)\s+", re.MULTILINE),
}

# En chunking
def _chunk_con_incisos(self, article_text, ...):
    """Detecta y separa incisos dentro de artÃ­culos."""

    incisos = self.legal_patterns["inciso"].finditer(article_text)

    # Si tiene > 5 incisos, crear sub-chunks
    if len(list(incisos)) > 5:
        return self._split_by_incisos(article_text, ...)
    else:
        return [self._create_chunk(text=article_text, ...)]
```

---

### Prioridad 5: GRAFO DE RELACIONES (Feature completa)

**Esto es mÃ¡s complejo y serÃ­a Fase 2, pero el diseÃ±o serÃ­a:**

```python
# Chunk con relaciones
chunk = {
    # ... campos existentes ...
    "parent_id": "chunk_id_del_capitulo",   # RelaciÃ³n padre
    "children_ids": ["chunk_1", "chunk_2"], # Relaciones hijos
    "references": ["anexo_8_chunk_id"],     # Referencias cruzadas
    "hierarchy_path": "TÃ­tulo 4 > CapÃ­tulo 2 > ArtÃ­culo 4.5.1",
}

# Query enhancement para navegaciÃ³n
if query == "Dame todos los artÃ­culos del CapÃ­tulo 2":
    # Buscar chunks con capitulo=2 y tipo=articulo
    # Ordenar por hierarchy_path
    # Retornar lista completa
```

---

## ğŸ“‹ PLAN DE IMPLEMENTACIÃ“N SUGERIDO

### Fase Inmediata (Arregla queries actuales)
1. âœ… Implementar chunking de anexos
2. âœ… Actualizar query enhancement para detectar anexos
3. âœ… Actualizar vectorizer para incluir `anexo_numero` en payload
4. âœ… Re-ingestar documentos

### Fase 2 (Mejora UX)
1. âœ… Extraer y guardar nombres de capÃ­tulos/tÃ­tulos
2. âœ… Actualizar prompts del LLM para usar nombres
3. âœ… Mejorar citaciones con nombres completos

### Fase 3 (Performance)
1. âœ… Implementar chunking inteligente adaptativo
2. âœ… Detectar y separar incisos/literales
3. âœ… Optimizar tamaÃ±o de chunks

### Fase 4 (Feature avanzada - opcional)
1. Crear grafo explÃ­cito de relaciones
2. Implementar navegaciÃ³n jerÃ¡rquica
3. VisualizaciÃ³n de estructura del documento

---

## ğŸ¯ RECOMENDACIÃ“N FINAL

**Empezar con Prioridad 1 (ANEXOS) inmediatamente** porque:
- Es el problema mÃ¡s urgente (bloquea queries vÃ¡lidas)
- Es relativamente sencillo de implementar
- Tiene impacto inmediato visible para el usuario
- Es generalizable a otros documentos que tengan anexos

**DespuÃ©s implementar Prioridad 2 (NOMBRES)** porque:
- Mejora significativamente la calidad de las respuestas
- No requiere cambios en la arquitectura
- Compatible con soluciÃ³n de anexos

**Dejar Prioridades 3-4 para iteraciones futuras** basadas en:
- Feedback real de usuarios
- AnÃ¡lisis de queries mÃ¡s comunes
- Performance medida en producciÃ³n
