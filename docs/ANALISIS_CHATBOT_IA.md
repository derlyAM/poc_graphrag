# AnÃ¡lisis: ImplementaciÃ³n de Chatbot IA Conversacional

**Fecha**: 2025-11-13
**Objetivo**: Chatbot interactivo sobre Inteligencia Artificial con modos de respuesta (corto/largo)

---

## ğŸ“‹ Requerimientos del Usuario

### Funcionalidad Esperada

1. **Ãrea fija**: Solo documentos del Ã¡rea "inteligencia_artificial"
2. **Conversacional**: InteracciÃ³n multi-turno (historial de mensajes)
3. **Anti-alucinaciÃ³n**: Respuestas estrictamente basadas en documentos del RAG
4. **Dos modos de respuesta**:
   - **Modo Corto**:
     - Respuestas concisas (2-3 oraciones)
     - Lista de documentos fuente (sin citas detalladas)
   - **Modo Largo**:
     - Respuestas detalladas
     - Citaciones inline especÃ­ficas [Art. X, Documento]

---

## âœ… Lo que YA Existe (Componentes Reutilizables)

### 1. Pipeline RAG Completo
```python
# src/pipeline.py
- âœ… QueryEnhancer: DetecciÃ³n de intenciÃ³n
- âœ… QueryDecomposer: Multihop para preguntas complejas
- âœ… HyDERetriever: HyDE Mejorado con templates especializados
- âœ… MultihopRetriever: BÃºsquedas iterativas
- âœ… VectorSearch: BÃºsqueda vectorial + BM25 hÃ­brida
- âœ… Reranker: Cross-encoder para re-ranking
- âœ… LLMClient: GeneraciÃ³n de respuestas
- âœ… CitationManager: Sistema de citaciones legales
- âœ… ResponseValidator: ValidaciÃ³n de completitud (Fase 3)
```

### 2. Documentos de IA Procesados
```
âœ… data_topic_IA/:
   - CONPES Colombia - PolÃ­tica nacional de inteligencia artificial.pdf
   - IEEE - EstÃ¡ndar global de Ã©tica en sistemas autÃ³nomos.pdf
   - La Inteligencia Artificial y su uso en el sector pÃºblico.pdf
   - INTELIGENCIA ARTIFICIAL - historia, evoluciÃ³n y aplicaciones.pdf
   - European Union Artificial Intelligence Act.pdf
   - UNESCO â€“ La inteligencia artificial Â¿Necesitamos una nueva educaciÃ³n?.pdf
   - IntroducciÃ³n a la IA Generativa Ametic.pdf
   - GuÃ­a sobre IA para estudiantes 2025.pdf
   - Facultad de IA Universidad de Caldas.pdf
```

### 3. Interfaz Streamlit Existente
```python
# app/streamlit_app.py
- âœ… Selector de Ã¡rea
- âœ… Filtro de documentos
- âœ… Input de pregunta
- âœ… Display de respuesta + fuentes
- âœ… MÃ©tricas de costos/tiempo
```

---

## âŒ Lo que FALTA Implementar

### 1. **GestiÃ³n de Historial Conversacional** (CRÃTICO)

**Problema actual**: El pipeline es stateless - cada query es independiente

**Ejemplos de limitaciones**:
```
Usuario: "Â¿QuÃ© es la inteligencia artificial?"
Bot: [Respuesta con definiciÃ³n de IA]

Usuario: "Â¿CuÃ¡les son sus aplicaciones?"  âŒ NO FUNCIONA
# El sistema no sabe que "sus" se refiere a "inteligencia artificial"
```

**SoluciÃ³n requerida**:
```python
class ConversationHistory:
    """
    Gestiona el historial de mensajes usuario-bot.
    """
    def __init__(self):
        self.messages = []  # Lista de {role: user/assistant, content: str}

    def add_message(self, role: str, content: str):
        """Agrega mensaje al historial."""

    def get_last_n_messages(self, n: int = 5):
        """Obtiene Ãºltimos N mensajes."""

    def clear(self):
        """Limpia el historial."""
```

**Archivos a crear**:
- `src/chatbot/conversation_manager.py`

---

### 2. **ReformulaciÃ³n Contextual de Queries** (CRÃTICO)

**Problema**: Queries con referencias ("eso", "lo anterior", "sus aplicaciones") no funcionan

**SoluciÃ³n**: Query Reformulation con LLM

```python
class QueryReformulator:
    """
    Reformula queries usando contexto conversacional.

    Convierte queries dependientes del contexto en queries standalone.
    """

    def reformulate_with_context(
        self,
        current_query: str,
        conversation_history: List[Dict]
    ) -> str:
        """
        Reformula query usando historial.

        Ejemplo:
            History:
                User: "Â¿QuÃ© es la IA?"
                Bot: "La IA es..."
            Current: "Â¿CuÃ¡les son sus aplicaciones?"
            Output: "Â¿CuÃ¡les son las aplicaciones de la inteligencia artificial?"
        """
```

**Prompt de reformulaciÃ³n**:
```python
REFORMULATION_PROMPT = """Dada la siguiente conversaciÃ³n, reformula la Ãºltima pregunta
del usuario para que sea independiente del contexto (standalone).

ConversaciÃ³n previa:
{conversation_history}

Pregunta actual del usuario:
{current_query}

Reformula la pregunta para que pueda entenderse sin el contexto anterior.
Si ya es standalone, devuÃ©lvela tal cual.

Pregunta reformulada:"""
```

**Archivos a crear**:
- `src/chatbot/query_reformulator.py`

---

### 3. **Modos de Respuesta (Corto vs Largo)** (NUEVO)

**Diferencias entre modos**:

| Aspecto | Modo Corto | Modo Largo |
|---------|-----------|------------|
| **Longitud** | 2-3 oraciones (50-100 tokens) | Completa (200-500 tokens) |
| **Citaciones** | NO inline | Inline completas [Art. X, Doc] |
| **Fuentes** | Lista al final (solo nombres) | Integradas en texto |
| **Temperatura** | 0.0 (mÃ¡s determinÃ­stica) | 0.1 (actual) |
| **Max tokens** | 150 | 600 (actual) |

**ImplementaciÃ³n**:

```python
class ResponseFormatter:
    """
    Formatea respuestas segÃºn el modo seleccionado.
    """

    def format_short_response(
        self,
        answer: str,
        chunks: List[Dict]
    ) -> Dict:
        """
        Modo Corto:
        - Extrae solo los primeros 2-3 pÃ¡rrafos
        - Remueve citaciones inline
        - Agrega lista de documentos Ãºnicos al final

        Returns:
            {
                "formatted_answer": str,
                "source_documents": List[str]  # Solo nombres
            }
        """

    def format_long_response(
        self,
        answer: str,
        chunks: List[Dict]
    ) -> Dict:
        """
        Modo Largo:
        - Mantiene respuesta completa
        - Mantiene citaciones inline
        - Agrega referencias detalladas

        Returns:
            {
                "formatted_answer": str,
                "detailed_sources": List[Dict]  # Con metadatos
            }
        """
```

**System prompts diferenciados**:

```python
# Modo Corto
SHORT_MODE_SYSTEM_PROMPT = """Eres un asistente experto en Inteligencia Artificial.

IMPORTANTE - MODO RESPUESTA CORTA:
1. Responde en MÃXIMO 2-3 oraciones concisas
2. NO incluyas citaciones en el texto (ej: [Art. X, Doc])
3. Ve directo al punto, sin introducciones largas
4. Si no hay informaciÃ³n, di "No encontrÃ© informaciÃ³n sobre esto"
5. Usa ÃšNICAMENTE el contexto proporcionado

Contexto: {context}

Pregunta: {question}"""

# Modo Largo
LONG_MODE_SYSTEM_PROMPT = """Eres un asistente experto en Inteligencia Artificial.

IMPORTANTE - MODO RESPUESTA DETALLADA:
1. Proporciona una respuesta completa y bien estructurada
2. TODA afirmaciÃ³n DEBE incluir citaciÃ³n: [Documento, SecciÃ³n/PÃ¡gina]
3. Organiza en secciones si aplica
4. Explica conceptos con detalle
5. Usa ÃšNICAMENTE el contexto proporcionado

Contexto: {context}

Pregunta: {question}"""
```

**Archivos a modificar**:
- `src/generation/llm_client.py` â†’ Agregar `generate_answer_short()` y `generate_answer_long()`
- `src/chatbot/response_formatter.py` â†’ NUEVO

---

### 4. **Reforzamiento Anti-AlucinaciÃ³n** (MEJORAR)

**Estrategias adicionales**:

#### A. Temperatura mÃ¡s baja
```python
# Modo Corto: temperatura = 0.0 (determinÃ­stica)
# Modo Largo: temperatura = 0.05 (mÃ¡s baja que actual 0.1)
```

#### B. Prompt mÃ¡s estricto
```python
ANTI_HALLUCINATION_RULES = """
REGLAS ESTRICTAS - NO ALUCINAR:
1. Si el contexto NO contiene la informaciÃ³n, di explÃ­citamente:
   "No encontrÃ© informaciÃ³n sobre [tema] en los documentos disponibles."
2. NUNCA uses conocimiento externo o general
3. NUNCA asumas o extrapoles mÃ¡s allÃ¡ del contexto
4. Si el contexto es ambiguo, indica la ambigÃ¼edad
5. NO inventes datos, fechas, nombres o cifras
"""
```

#### C. ValidaciÃ³n post-generaciÃ³n (ya existe)
```python
# ResponseValidator (Fase 3) - ya implementado
# - Valida completitud
# - Detecta respuestas vagas
# - Auto-retry si incompleto
```

#### D. Chunking con evidencia
```python
def build_context_with_evidence(chunks: List[Dict]) -> str:
    """
    Construye contexto marcando claramente quÃ© es evidencia real.
    """
    context = "=== EVIDENCIA DISPONIBLE ===\n\n"

    for i, chunk in enumerate(chunks):
        context += f"[EVIDENCIA {i+1}]\n"
        context += f"Documento: {chunk['documento_nombre']}\n"
        context += f"SecciÃ³n: {chunk.get('seccion_nombre', 'N/A')}\n"
        context += f"Contenido:\n{chunk['texto']}\n\n"

    context += "=== FIN DE EVIDENCIA ===\n"
    context += "IMPORTANTE: Solo usa la EVIDENCIA anterior. No agregues informaciÃ³n externa.\n"

    return context
```

**Archivos a modificar**:
- `src/generation/llm_client.py` â†’ Agregar prompts anti-alucinaciÃ³n
- `src/chatbot/anti_hallucination.py` â†’ NUEVO (validadores adicionales)

---

### 5. **Interfaz de Chatbot en Streamlit** (NUEVO)

**DiseÃ±o propuesto**:

```python
# app/pages/2_Chatbot_IA.py (NUEVO ARCHIVO)

import streamlit as st
from src.chatbot.conversational_pipeline import ConversationalPipeline

st.set_page_config(page_title="Chatbot IA", page_icon="ğŸ¤–")

# TÃ­tulo
st.title("ğŸ¤– Chatbot de Inteligencia Artificial")
st.caption("PregÃºntame sobre IA - respuestas basadas en documentos acadÃ©micos")

# ConfiguraciÃ³n en sidebar
with st.sidebar:
    st.header("âš™ï¸ ConfiguraciÃ³n")

    # Modo de respuesta
    response_mode = st.radio(
        "Modo de respuesta",
        ["Corto", "Largo"],
        help="Corto: conciso + lista docs. Largo: detallado + citas"
    )

    # Filtro de documentos (opcional)
    available_docs = get_ia_documents()
    selected_docs = st.multiselect(
        "Filtrar documentos (opcional)",
        options=[doc['nombre'] for doc in available_docs],
        help="VacÃ­o = todos los documentos de IA"
    )

    # BotÃ³n limpiar chat
    if st.button("ğŸ—‘ï¸ Limpiar conversaciÃ³n"):
        st.session_state.messages = []
        st.session_state.conversation_history.clear()
        st.rerun()

# Inicializar pipeline y historial
if "chatbot_pipeline" not in st.session_state:
    st.session_state.chatbot_pipeline = ConversationalPipeline(area="inteligencia_artificial")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

        # Mostrar fuentes si es mensaje del asistente
        if message["role"] == "assistant" and "sources" in message:
            with st.expander("ğŸ“š Fuentes"):
                for source in message["sources"]:
                    st.write(f"- {source}")

# Chat input
if prompt := st.chat_input("PregÃºntame sobre Inteligencia Artificial..."):
    # Agregar mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    # Generar respuesta
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            # Usar pipeline conversacional
            result = st.session_state.chatbot_pipeline.query(
                question=prompt,
                response_mode=response_mode.lower(),
                documento_ids=selected_doc_ids if selected_docs else None
            )

            # Mostrar respuesta
            st.markdown(result["answer"])

            # Mostrar fuentes
            with st.expander("ğŸ“š Fuentes"):
                for source in result["sources"]:
                    st.write(f"- {source}")

            # Agregar a historial
            st.session_state.messages.append({
                "role": "assistant",
                "content": result["answer"],
                "sources": result["sources"]
            })
```

**Archivos a crear**:
- `app/pages/2_Chatbot_IA.py`

**Beneficios de Streamlit Pages**:
- NavegaciÃ³n automÃ¡tica en sidebar
- Estado independiente por pÃ¡gina
- Mejor organizaciÃ³n

---

### 6. **Pipeline Conversacional** (NUEVO - COMPONENTE PRINCIPAL)

```python
# src/chatbot/conversational_pipeline.py

from typing import List, Dict, Optional
from loguru import logger

from src.pipeline import Pipeline
from src.chatbot.conversation_manager import ConversationHistory
from src.chatbot.query_reformulator import QueryReformulator
from src.chatbot.response_formatter import ResponseFormatter


class ConversationalPipeline:
    """
    Pipeline especializado para chatbot conversacional.

    Extiende Pipeline base con:
    - GestiÃ³n de historial
    - ReformulaciÃ³n contextual de queries
    - Formateo segÃºn modo (corto/largo)
    """

    def __init__(self, area: str = "inteligencia_artificial"):
        """
        Inicializa pipeline conversacional.

        Args:
            area: Ãrea fija (por defecto IA)
        """
        self.area = area
        self.base_pipeline = Pipeline()
        self.conversation_history = ConversationHistory()
        self.query_reformulator = QueryReformulator()
        self.response_formatter = ResponseFormatter()

        logger.info(f"ConversationalPipeline initialized for area: {area}")

    def query(
        self,
        question: str,
        response_mode: str = "long",  # "short" or "long"
        documento_ids: Optional[List[str]] = None,
        max_history: int = 5
    ) -> Dict:
        """
        Procesa query conversacional.

        Steps:
        1. Reformula query con contexto del historial
        2. Ejecuta RAG pipeline base
        3. Formatea respuesta segÃºn modo
        4. Actualiza historial

        Args:
            question: Pregunta del usuario
            response_mode: "short" o "long"
            documento_ids: Filtro de documentos (opcional)
            max_history: NÃºmero de mensajes previos a considerar

        Returns:
            {
                "answer": str,
                "sources": List[str],  # Nombres de documentos
                "reformulated_query": str,
                "chunks_used": int,
                "cost": float,
                "response_mode": str
            }
        """
        logger.info(f"Processing conversational query (mode: {response_mode})")

        # STEP 1: Reformular query con contexto
        history = self.conversation_history.get_last_n_messages(max_history)

        if history:
            reformulated_query = self.query_reformulator.reformulate_with_context(
                current_query=question,
                conversation_history=history
            )
            logger.info(f"Query reformulated: '{question}' â†’ '{reformulated_query}'")
        else:
            reformulated_query = question

        # STEP 2: Ejecutar RAG pipeline
        # Configurar segÃºn modo
        if response_mode == "short":
            # Modo corto: menos chunks, temperatura mÃ¡s baja
            rag_result = self.base_pipeline.query(
                question=reformulated_query,
                area=self.area,
                documento_ids=documento_ids,
                top_k_retrieval=10,  # Menos chunks
                enable_reranking=True,
                enable_multihop=False,  # Respuestas cortas no necesitan multihop
                enable_hyde=True,
                enable_validation=False  # ValidaciÃ³n solo en modo largo
            )
        else:  # long
            # Modo largo: mÃ¡s chunks, validaciÃ³n activa
            rag_result = self.base_pipeline.query(
                question=reformulated_query,
                area=self.area,
                documento_ids=documento_ids,
                top_k_retrieval=20,
                enable_reranking=True,
                enable_multihop=True,
                enable_hyde=True,
                enable_validation=True  # ValidaciÃ³n de completitud
            )

        # STEP 3: Formatear respuesta segÃºn modo
        if response_mode == "short":
            formatted = self.response_formatter.format_short_response(
                answer=rag_result["answer"],
                chunks=rag_result["chunks"]
            )
        else:
            formatted = self.response_formatter.format_long_response(
                answer=rag_result["answer"],
                chunks=rag_result["chunks"]
            )

        # STEP 4: Actualizar historial
        self.conversation_history.add_message("user", question)
        self.conversation_history.add_message("assistant", formatted["formatted_answer"])

        # Return result
        return {
            "answer": formatted["formatted_answer"],
            "sources": formatted.get("source_documents", formatted.get("detailed_sources", [])),
            "reformulated_query": reformulated_query,
            "chunks_used": len(rag_result["chunks"]),
            "cost": rag_result["total_cost"],
            "response_mode": response_mode,
            "original_query": question
        }

    def clear_history(self):
        """Limpia el historial de conversaciÃ³n."""
        self.conversation_history.clear()
        logger.info("Conversation history cleared")

    def get_history(self) -> List[Dict]:
        """Obtiene el historial completo."""
        return self.conversation_history.messages
```

**Archivos a crear**:
- `src/chatbot/conversational_pipeline.py`

---

## ğŸ“ Estructura de Archivos a Crear/Modificar

### Nuevos Archivos

```
src/chatbot/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conversational_pipeline.py     # Pipeline principal del chatbot
â”œâ”€â”€ conversation_manager.py        # GestiÃ³n de historial
â”œâ”€â”€ query_reformulator.py          # ReformulaciÃ³n contextual
â”œâ”€â”€ response_formatter.py          # Formateo corto/largo
â””â”€â”€ anti_hallucination.py          # Validadores anti-alucinaciÃ³n

app/pages/
â””â”€â”€ 2_Chatbot_IA.py                # Interfaz Streamlit del chatbot

tests/
â””â”€â”€ test_chatbot.py                # Tests del chatbot
```

### Archivos a Modificar

```
src/generation/llm_client.py
  â†³ Agregar: generate_answer_short(), generate_answer_long()
  â†³ Agregar: system prompts diferenciados

src/pipeline.py
  â†³ Modificar: Agregar parÃ¡metro response_mode (opcional, para compatibilidad)

app/streamlit_app.py
  â†³ Modificar: Agregar link/botÃ³n a pÃ¡gina de chatbot
```

---

## ğŸ”„ Flujo de InteracciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USUARIO: "Â¿QuÃ© es la inteligencia artificial?"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ConversationalPipeline                                          â”‚
â”‚  1. Historial vacÃ­o â†’ Query no cambia                           â”‚
â”‚  2. RAG Pipeline: Retrieval + Generation                        â”‚
â”‚  3. Formato segÃºn modo (corto/largo)                            â”‚
â”‚  4. Guarda en historial: user + assistant                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESPUESTA (Modo Corto):                                         â”‚
â”‚  "La IA es la capacidad de mÃ¡quinas para realizar tareas que    â”‚
â”‚  normalmente requieren inteligencia humana, como aprendizaje    â”‚
â”‚  y toma de decisiones."                                          â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“š Fuentes:                                                     â”‚
â”‚  - CONPES Colombia - PolÃ­tica nacional de IA                    â”‚
â”‚  - IntroducciÃ³n a la IA Generativa Ametic                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USUARIO: "Â¿CuÃ¡les son sus aplicaciones en el sector pÃºblico?" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ConversationalPipeline                                          â”‚
â”‚  1. Historial: [Q: "Â¿QuÃ© es IA?", A: "La IA es..."]            â”‚
â”‚  2. QueryReformulator:                                           â”‚
â”‚     "sus aplicaciones" â†’ "aplicaciones de la inteligencia       â”‚
â”‚      artificial en el sector pÃºblico"                           â”‚
â”‚  3. RAG Pipeline con query reformulada                          â”‚
â”‚  4. Formato segÃºn modo                                           â”‚
â”‚  5. Guarda en historial                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                    [Respuesta...]
```

---

## ğŸ’° EstimaciÃ³n de Costos

### Por ConversaciÃ³n (estimado)

| Componente | Tokens | Costo |
|------------|--------|-------|
| Query Reformulation (si aplica) | 200-300 | $0.00003 |
| RAG Pipeline (retrieval + generation) | 2000-3000 | $0.00045 |
| ValidaciÃ³n (solo modo largo) | 300-400 | $0.00006 |
| **Total por turno** | **2500-3700** | **~$0.00054** |

**ConversaciÃ³n tÃ­pica (5 turnos)**: ~$0.0027 (menos de 1 centavo)

**1000 conversaciones/mes**: ~$2.70

---

## â±ï¸ EstimaciÃ³n de Esfuerzo

| Tarea | Complejidad | Tiempo Estimado |
|-------|-------------|-----------------|
| 1. ConversationHistory | Baja | 30 min |
| 2. QueryReformulator | Media | 1.5 horas |
| 3. ResponseFormatter | Baja | 1 hora |
| 4. Prompts anti-alucinaciÃ³n | Media | 1 hora |
| 5. ConversationalPipeline | Alta | 2 horas |
| 6. Interfaz Streamlit Chatbot | Media | 1.5 horas |
| 7. Tests y debugging | Media | 2 horas |
| **TOTAL** | - | **9-10 horas** |

---

## ğŸ¯ Prioridades de ImplementaciÃ³n

### Fase 1 (MVP - 4 horas)
1. âœ… ConversationHistory bÃ¡sico
2. âœ… ConversationalPipeline sin reformulaciÃ³n
3. âœ… Interfaz Streamlit bÃ¡sica
4. âœ… Modo largo (reusar pipeline actual)

**Resultado**: Chatbot funcional con historial bÃ¡sico, solo modo largo

### Fase 2 (Modos - 3 horas)
5. âœ… ResponseFormatter (corto/largo)
6. âœ… Prompts diferenciados
7. âœ… Selector de modo en UI

**Resultado**: Chatbot con modos corto/largo

### Fase 3 (Contextual - 3 horas)
8. âœ… QueryReformulator
9. âœ… IntegraciÃ³n en ConversationalPipeline
10. âœ… Tests de reformulaciÃ³n

**Resultado**: Chatbot completamente conversacional

---

## ğŸ§ª Plan de Testing

### Tests Unitarios

```python
# tests/test_chatbot.py

def test_conversation_history():
    """Test que historial se almacena correctamente."""

def test_query_reformulation():
    """Test reformulaciÃ³n con contexto."""
    # Input: "Â¿CuÃ¡les son sus aplicaciones?"
    # History: [User: "Â¿QuÃ© es IA?", Bot: "..."]
    # Expected: "Â¿CuÃ¡les son las aplicaciones de la IA?"

def test_short_mode():
    """Test modo corto: mÃ¡x 3 oraciones, sin citas inline."""

def test_long_mode():
    """Test modo largo: citas inline presentes."""

def test_anti_hallucination():
    """Test que no alucina cuando no hay contexto."""
    # Query sobre tema no en documentos
    # Expected: "No encontrÃ© informaciÃ³n sobre..."
```

### Tests de IntegraciÃ³n

```python
def test_full_conversation():
    """Test conversaciÃ³n completa multi-turno."""
    # Turno 1: Pregunta sobre definiciÃ³n
    # Turno 2: Pregunta con referencia ("sus aplicaciones")
    # Turno 3: Pregunta de seguimiento
    # Validar: reformulaciÃ³n correcta, respuestas coherentes
```

---

## ğŸš€ CÃ³mo Empezar

### Orden de ImplementaciÃ³n Sugerido

**DÃ­a 1: Base conversacional** (4 horas)
1. Crear `src/chatbot/conversation_manager.py`
2. Crear `src/chatbot/conversational_pipeline.py` (versiÃ³n simple)
3. Crear `app/pages/2_Chatbot_IA.py` (interfaz bÃ¡sica)
4. Testing: Chatbot funcional sin reformulaciÃ³n

**DÃ­a 2: Modos de respuesta** (3 horas)
5. Crear `src/chatbot/response_formatter.py`
6. Modificar `src/generation/llm_client.py` (prompts)
7. Integrar en ConversationalPipeline
8. Testing: Modos corto/largo funcionan

**DÃ­a 3: Contextual** (3 horas)
9. Crear `src/chatbot/query_reformulator.py`
10. Integrar en ConversationalPipeline
11. Testing completo
12. DocumentaciÃ³n

---

## ğŸ“ Notas Adicionales

### Consideraciones de UX

1. **Indicador de pensamiento**: Mostrar "Pensando..." mientras procesa
2. **Streaming (opcional)**: Respuestas palabra por palabra (requiere SSE)
3. **BotÃ³n de retry**: Si respuesta no satisface, regenerar
4. **Exportar conversaciÃ³n**: BotÃ³n para descargar chat como TXT/MD
5. **Sugerencias de preguntas**: Mostrar 3-4 preguntas frecuentes

### Mejoras Futuras (No prioritarias)

- **Memoria a largo plazo**: Guardar conversaciones en base de datos
- **PersonalizaciÃ³n**: Tono de respuestas (formal/informal)
- **Multi-idioma**: Soporte para inglÃ©s
- **Feedback**: Thumbs up/down en respuestas
- **Analytics**: Dashboard de preguntas frecuentes

---

## âœ… Checklist de ImplementaciÃ³n

- [ ] 1. ConversationHistory creado
- [ ] 2. QueryReformulator creado
- [ ] 3. ResponseFormatter creado
- [ ] 4. Prompts anti-alucinaciÃ³n agregados
- [ ] 5. ConversationalPipeline creado
- [ ] 6. Interfaz Streamlit creada
- [ ] 7. Tests unitarios pasando
- [ ] 8. Tests de integraciÃ³n pasando
- [ ] 9. DocumentaciÃ³n actualizada
- [ ] 10. README con instrucciones de uso

---

**Fecha de anÃ¡lisis**: 2025-11-13
**Autor**: Claude Code
**VersiÃ³n**: 1.0
